{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(r\".\\malicious\\WebOS_binary.csv\") #\n",
    "df2 = pd.read_csv(r\".\\malicious\\Server_Binary.csv\") #\n",
    "df3 = pd.read_csv(r\".\\malicious\\Raspberry_Webmine_Robust.csv\")\n",
    "df4 = pd.read_csv(r\".\\malicious\\Raspberry_Binary.csv\") #\n",
    "df5 = pd.read_csv(r\".\\malicious\\Raspberry_Webmine_Aggressive.csv\")\n",
    "df6 = pd.read_csv(r\".\\malicious\\Raspberry_WebminePool_Aggressive.csv\")\n",
    "df7 = pd.read_csv(r\".\\malicious\\Server_WebminePool_Aggressive.csv\") #\n",
    "df32 = pd.read_csv(r\".\\malicious\\Server_WebminePool_Robust.csv\") #\n",
    "df33 = pd.read_csv(r\".\\malicious\\Raspberry_WebminePool_Stealthy.csv\") #\n",
    "df34 = pd.read_csv(r\".\\malicious\\Raspberry_WebminePool_Robust.csv\") #\n",
    "df35 = pd.read_csv(r\".\\malicious\\Desktop_WebminePool_Aggressive.csv\") #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign-1 csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df8 = pd.read_csv(r\".\\benign-1\\interactive_01.csv\") #\n",
    "df9 = pd.read_csv(r\".\\benign-1\\interactive_02.csv\") #\n",
    "df10 = pd.read_csv(r\".\\benign-1\\interactive_03.csv\") #\n",
    "df11 = pd.read_csv(r\".\\benign-1\\interactive_04.csv\") #\n",
    "df12 = pd.read_csv(r\".\\benign-1\\interactive_05.csv\") #\n",
    "df13 = pd.read_csv(r\".\\benign-1\\interactive_06.csv\") #\n",
    "df14 = pd.read_csv(r\".\\benign-1\\web_1page_01.csv\") #\n",
    "df15 = pd.read_csv(r\".\\benign-1\\web_1page_02.csv\") #\n",
    "df16 = pd.read_csv(r\".\\benign-1\\web_1page_03.csv\") #\n",
    "df17 = pd.read_csv(r\".\\benign-1\\web_1page_04.csv\") #\n",
    "df18 = pd.read_csv(r\".\\benign-1\\web_1page_05.csv\") #\n",
    "df19 = pd.read_csv(r\".\\benign-1\\bulk_xs_04.csv\") #\n",
    "df20 = pd.read_csv(r\".\\benign-1\\bulk_xs_05.csv\") #\n",
    "df21 = pd.read_csv(r\".\\benign-1\\video_180s480p_01.csv\") #\n",
    "df22 = pd.read_csv(r\".\\benign-1\\video_180s480p_02.csv\") #\n",
    "df23 = pd.read_csv(r\".\\benign-1\\video_x1_04.csv\") #\n",
    "df24 = pd.read_csv(r\".\\benign-1\\web_multiple_04.csv\") #\n",
    "df25 = pd.read_csv(r\".\\benign-1\\bulk_xs_01.csv\") #\n",
    "df26 = pd.read_csv(r\".\\benign-1\\bulk_xs_09.csv\") #\n",
    "df27 = pd.read_csv(r\".\\benign-1\\bulk_xs_06.csv\") #\n",
    "df28 = pd.read_csv(r\".\\benign-1\\bulk_xs_03.csv\") #\n",
    "df29 = pd.read_csv(r\".\\benign-1\\web_multiple_03.csv\") #\n",
    "df30 = pd.read_csv(r\".\\benign-1\\web_multiple_05.csv\") #\n",
    "df31 = pd.read_csv(r\".\\benign-1\\web_multiple_06.csv\") #\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59635\n",
      "df25 -->> 625216\n",
      "df26 -->> 266935\n",
      "df27 -->> 453471\n",
      "df28 -->> 654495\n",
      "df29 -->> 6764\n",
      "df30 -->> 25300\n",
      "df31 -->> 3689\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n",
    "print(\"df24 -->> {}\".format(len(df24)))\n",
    "print(\"df25 -->> {}\".format(len(df25)))\n",
    "print(\"df26 -->> {}\".format(len(df26)))\n",
    "print(\"df27 -->> {}\".format(len(df27)))\n",
    "print(\"df28 -->> {}\".format(len(df28)))\n",
    "print(\"df29 -->> {}\".format(len(df29)))\n",
    "print(\"df30 -->> {}\".format(len(df30)))\n",
    "print(\"df31 -->> {}\".format(len(df31)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#                     Filtering                                 #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "df24.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df25.insert(7, \"Is_malicious\", 0)\n",
    "df26.insert(7, \"Is_malicious\", 0)\n",
    "df27.insert(7, \"Is_malicious\", 0)\n",
    "df28.insert(7, \"Is_malicious\", 0)\n",
    "df29.insert(7, \"Is_malicious\", 0)\n",
    "df30.insert(7, \"Is_malicious\", 0)\n",
    "df31.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 41572\n",
      "df2 -->> 1198039\n",
      "df3 -->> 3519\n",
      "df4 -->> 11745\n",
      "df5 -->> 12871\n",
      "df6 -->> 19643\n",
      "df7 -->> 2539\n",
      "df8 -->> 4550\n",
      "df9 -->> 3869\n",
      "df10 -->> 5327\n",
      "df11 -->> 4727\n",
      "df12 -->> 4190\n",
      "df13 -->> 3481\n",
      "df14 -->> 38576\n",
      "df15 -->> 5961\n",
      "df16 -->> 1803\n",
      "df17 -->> 7029\n",
      "df18 -->> 1012\n",
      "df19 -->> 96545\n",
      "df20 -->> 108065\n",
      "df21 -->> 25138\n",
      "df22 -->> 91274\n",
      "df23 -->> 23597\n",
      "df24 -->> 59619\n",
      "df25 -->> 625194\n",
      "df26 -->> 266935\n",
      "df27 -->> 453466\n",
      "df28 -->> 654479\n",
      "df29 -->> 6764\n",
      "df30 -->> 25288\n",
      "df31 -->> 3689\n",
      "df32 -->> 16744\n",
      "df33 -->> 9880\n",
      "df34 -->> 6406\n",
      "df35 -->> 234272\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1.dropna())))\n",
    "print(\"df2 -->> {}\".format(len(df2.dropna())))\n",
    "print(\"df3 -->> {}\".format(len(df3.dropna())))\n",
    "print(\"df4 -->> {}\".format(len(df4.dropna())))\n",
    "print(\"df5 -->> {}\".format(len(df5.dropna())))\n",
    "print(\"df6 -->> {}\".format(len(df6.dropna())))\n",
    "print(\"df7 -->> {}\".format(len(df7.dropna())))\n",
    "print(\"df8 -->> {}\".format(len(df8.dropna())))\n",
    "print(\"df9 -->> {}\".format(len(df9.dropna())))\n",
    "print(\"df10 -->> {}\".format(len(df10.dropna())))\n",
    "print(\"df11 -->> {}\".format(len(df11.dropna())))\n",
    "print(\"df12 -->> {}\".format(len(df12.dropna())))\n",
    "print(\"df13 -->> {}\".format(len(df13.dropna())))\n",
    "print(\"df14 -->> {}\".format(len(df14.dropna())))\n",
    "print(\"df15 -->> {}\".format(len(df15.dropna())))\n",
    "print(\"df16 -->> {}\".format(len(df16.dropna())))\n",
    "print(\"df17 -->> {}\".format(len(df17.dropna())))\n",
    "print(\"df18 -->> {}\".format(len(df18.dropna())))\n",
    "print(\"df19 -->> {}\".format(len(df19.dropna())))\n",
    "print(\"df20 -->> {}\".format(len(df20.dropna())))\n",
    "print(\"df21 -->> {}\".format(len(df21.dropna())))\n",
    "print(\"df22 -->> {}\".format(len(df22.dropna())))\n",
    "print(\"df23 -->> {}\".format(len(df23.dropna())))\n",
    "print(\"df24 -->> {}\".format(len(df24.dropna())))\n",
    "print(\"df25 -->> {}\".format(len(df25.dropna())))\n",
    "print(\"df26 -->> {}\".format(len(df26.dropna())))\n",
    "print(\"df27 -->> {}\".format(len(df27.dropna())))\n",
    "print(\"df28 -->> {}\".format(len(df28.dropna())))\n",
    "print(\"df29 -->> {}\".format(len(df29.dropna())))\n",
    "print(\"df30 -->> {}\".format(len(df30.dropna())))\n",
    "print(\"df31 -->> {}\".format(len(df31.dropna())))\n",
    "print(\"df32 -->> {}\".format(len(df32.dropna())))\n",
    "print(\"df33 -->> {}\".format(len(df33.dropna())))\n",
    "print(\"df34 -->> {}\".format(len(df34.dropna())))\n",
    "print(\"df35 -->> {}\".format(len(df35.dropna())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b):\n",
    "    \n",
    "    df_malicious = a.copy()\n",
    "    df_benign    = b.copy()\n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious['id']= np.floor(df_malicious.index.array/10)\n",
    "    df_benign.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign['id']= np.floor(df_benign.index.array/10)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "\n",
    "    \n",
    "    \n",
    "    tf2=tsfresh.extract_features(df_benign,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "\n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "\n",
    "    features=pd.concat([tf1,tf2])\n",
    "\n",
    "\n",
    "    features2 = features.copy()\n",
    "    features2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    y = pd.Series(data = features2['class'], index=features2.index)\n",
    "    \n",
    "    from tsfresh.examples import load_robot_execution_failures\n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "    relevance_table = calculate_relevance_table(features2, y)\n",
    "    relevance_table = relevance_table[relevance_table.relevant]\n",
    "    relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "\n",
    "    relevance_table\n",
    "    \n",
    "    best_features = relevance_table[relevance_table['p_value'] <= 0.05]\n",
    "\n",
    "    df_ML = pd.DataFrame()\n",
    "\n",
    "    for pkt in best_features:\n",
    "        df_ML[best_features.feature] = features[best_features.feature]\n",
    "\n",
    "    final = ML_Process(df_ML)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML):\n",
    "    #df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    #X = df_finalized[['Time', 'Length','Protocol']].values\n",
    "    X = df_ML.drop('class',axis=1).to_numpy()\n",
    "    #y = df_finalized[['Is_malicious']]\n",
    "    y = df_ML['class'].to_numpy()\n",
    "\n",
    "\n",
    "    #print(X,y)\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X[0])):\n",
    "        X[:, i] = Le.fit_transform(X[:, i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "        ('SVM-linear-scale-1', SVC(C = 1, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-1', SVC(C = 1, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-1', SVC(C = 1, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-1', SVC(C = 1, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-1', SVC(C = 1, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-1', SVC(C = 1, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-1', SVC(C = 1, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-1', SVC(C = 1, kernel = 'sigmoid',gamma ='auto')),\n",
    "        ('SVM-linear-scale-2', SVC(C = 2, kernel = 'linear',gamma ='scale')),\n",
    "        ('SVM-poly-scale-2', SVC(C = 2, kernel = 'poly',gamma ='scale')),\n",
    "        ('SVM-rbf-scale-2', SVC(C = 2, kernel = 'rbf',gamma ='scale')),\n",
    "        ('SVM-sigmoid-scale-2', SVC(C = 2, kernel = 'sigmoid',gamma ='scale')),\n",
    "        ('SVM-linear-auto-2', SVC(C = 2, kernel = 'linear',gamma ='auto')),\n",
    "        ('SVM-poly-auto-2', SVC(C = 2, kernel = 'poly',gamma ='auto')),\n",
    "        ('SVM-rbf-auto-2', SVC(C = 2, kernel = 'rbf',gamma ='auto')),\n",
    "        ('SVM-sigmoid-auto-2', SVC(C = 2, kernel = 'sigmoid',gamma ='auto'))\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        #df_resulta = df_results.append(dfs)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1000\n",
      "benign: 1000\n",
      "0 NAN in malicious!\n",
      "0 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1000\n",
      "benign: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 34/34 [00:02<00:00, 12.73it/s]\n",
      "Feature Extraction: 100%|██████████| 34/34 [00:02<00:00, 14.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "SVM-linear-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.78      0.91      0.84        23\n",
      "      benign       0.91      0.78      0.84        27\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.85      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.004999    0.005002       0.833333                 0.845295   \n",
      "1  0.004997    0.005004       0.833333                 0.833333   \n",
      "2  0.001997    0.005002       0.833333                 0.849170   \n",
      "3  0.003997    0.004003       0.800000                 0.800000   \n",
      "4  0.004001    0.008000       0.700000                 0.700893   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.833333          0.830476      0.866071  SVM-linear-scale-1  \n",
      "1              0.833333          0.832381      0.814480  SVM-linear-scale-1  \n",
      "2              0.833333          0.832777      0.875000  SVM-linear-scale-1  \n",
      "3              0.800000          0.800000      0.853333  SVM-linear-scale-1  \n",
      "4              0.700000          0.699666      0.848889  SVM-linear-scale-1  \n",
      "SVM-poly-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      0.96      0.90        23\n",
      "      benign       0.96      0.85      0.90        27\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.90      0.90      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.004999    0.005002       0.833333                 0.845295   \n",
      "1  0.004997    0.005004       0.833333                 0.833333   \n",
      "2  0.001997    0.005002       0.833333                 0.849170   \n",
      "3  0.003997    0.004003       0.800000                 0.800000   \n",
      "4  0.004001    0.008000       0.700000                 0.700893   \n",
      "5  0.002000    0.005001       0.900000                 0.902222   \n",
      "6  0.001011    0.004992       0.833333                 0.851190   \n",
      "7  0.001997    0.005007       0.933333                 0.933333   \n",
      "8  0.000994    0.005002       0.833333                 0.834821   \n",
      "9  0.000998    0.005003       0.900000                 0.901786   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0              0.833333          0.830476      0.866071  SVM-linear-scale-1  \n",
      "1              0.833333          0.832381      0.814480  SVM-linear-scale-1  \n",
      "2              0.833333          0.832777      0.875000  SVM-linear-scale-1  \n",
      "3              0.800000          0.800000      0.853333  SVM-linear-scale-1  \n",
      "4              0.700000          0.699666      0.848889  SVM-linear-scale-1  \n",
      "5              0.900000          0.900111      0.852679    SVM-poly-scale-1  \n",
      "6              0.833333          0.833890      0.837104    SVM-poly-scale-1  \n",
      "7              0.933333          0.933333      0.924107    SVM-poly-scale-1  \n",
      "8              0.833333          0.833148      0.871111    SVM-poly-scale-1  \n",
      "9              0.900000          0.899889      0.982222    SVM-poly-scale-1  \n",
      "SVM-rbf-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      1.00      0.92        23\n",
      "      benign       1.00      0.85      0.92        27\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.93      0.92        50\n",
      "weighted avg       0.93      0.92      0.92        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.833333          0.830476      0.866071  SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480  SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000  SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333  SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889  SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679    SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104    SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107    SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111    SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222    SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714     SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552     SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643     SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222     SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667     SVM-rbf-scale-1  \n",
      "SVM-sigmoid-scale-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.56      0.65      0.60        23\n",
      "      benign       0.65      0.56      0.60        27\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.60      0.60      0.60        50\n",
      "weighted avg       0.61      0.60      0.60        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "SVM-linear-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.78      0.91      0.84        23\n",
      "      benign       0.91      0.78      0.84        27\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.85      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "SVM-poly-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.84      0.91      0.88        23\n",
      "      benign       0.92      0.85      0.88        27\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.88      0.88        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "25  0.001996    0.004996       0.866667                 0.874405   \n",
      "26  0.002003    0.004002       0.800000                 0.800000   \n",
      "27  0.001000    0.004999       0.833333                 0.835556   \n",
      "28  0.001002    0.004998       0.733333                 0.737557   \n",
      "29  0.001001    0.005000       0.766667                 0.800000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.848214      SVM-poly-auto-1  \n",
      "26              0.800000          0.800000      0.850679      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.892857      SVM-poly-auto-1  \n",
      "28              0.733333          0.732143      0.760000      SVM-poly-auto-1  \n",
      "29              0.766667          0.760000      0.915556      SVM-poly-auto-1  \n",
      "SVM-rbf-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.47      1.00      0.64        23\n",
      "      benign       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.73      0.52      0.36        50\n",
      "weighted avg       0.76      0.48      0.33        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "25  0.001996    0.004996       0.866667                 0.874405   \n",
      "26  0.002003    0.004002       0.800000                 0.800000   \n",
      "27  0.001000    0.004999       0.833333                 0.835556   \n",
      "28  0.001002    0.004998       0.733333                 0.737557   \n",
      "29  0.001001    0.005000       0.766667                 0.800000   \n",
      "30  0.000999    0.005002       0.533333                 0.284444   \n",
      "31  0.001000    0.005000       0.566667                 0.321111   \n",
      "32  0.001000    0.006000       0.466667                 0.217778   \n",
      "33  0.000999    0.005000       0.500000                 0.250000   \n",
      "34  0.001000    0.005004       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.848214      SVM-poly-auto-1  \n",
      "26              0.800000          0.800000      0.850679      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.892857      SVM-poly-auto-1  \n",
      "28              0.733333          0.732143      0.760000      SVM-poly-auto-1  \n",
      "29              0.766667          0.760000      0.915556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "SVM-sigmoid-auto-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.46      1.00      0.63        23\n",
      "      benign       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.23      0.50      0.32        50\n",
      "weighted avg       0.21      0.46      0.29        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "25  0.001996    0.004996       0.866667                 0.874405   \n",
      "26  0.002003    0.004002       0.800000                 0.800000   \n",
      "27  0.001000    0.004999       0.833333                 0.835556   \n",
      "28  0.001002    0.004998       0.733333                 0.737557   \n",
      "29  0.001001    0.005000       0.766667                 0.800000   \n",
      "30  0.000999    0.005002       0.533333                 0.284444   \n",
      "31  0.001000    0.005000       0.566667                 0.321111   \n",
      "32  0.001000    0.006000       0.466667                 0.217778   \n",
      "33  0.000999    0.005000       0.500000                 0.250000   \n",
      "34  0.001000    0.005004       0.500000                 0.250000   \n",
      "35  0.002002    0.004008       0.533333                 0.284444   \n",
      "36  0.000999    0.004998       0.433333                 0.187778   \n",
      "37  0.001002    0.004996       0.466667                 0.217778   \n",
      "38  0.001069    0.003949       0.500000                 0.250000   \n",
      "39  0.000977    0.005014       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.848214      SVM-poly-auto-1  \n",
      "26              0.800000          0.800000      0.850679      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.892857      SVM-poly-auto-1  \n",
      "28              0.733333          0.732143      0.760000      SVM-poly-auto-1  \n",
      "29              0.766667          0.760000      0.915556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "SVM-linear-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.78      0.91      0.84        23\n",
      "      benign       0.91      0.78      0.84        27\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.85      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "25  0.001996    0.004996       0.866667                 0.874405   \n",
      "26  0.002003    0.004002       0.800000                 0.800000   \n",
      "27  0.001000    0.004999       0.833333                 0.835556   \n",
      "28  0.001002    0.004998       0.733333                 0.737557   \n",
      "29  0.001001    0.005000       0.766667                 0.800000   \n",
      "30  0.000999    0.005002       0.533333                 0.284444   \n",
      "31  0.001000    0.005000       0.566667                 0.321111   \n",
      "32  0.001000    0.006000       0.466667                 0.217778   \n",
      "33  0.000999    0.005000       0.500000                 0.250000   \n",
      "34  0.001000    0.005004       0.500000                 0.250000   \n",
      "35  0.002002    0.004008       0.533333                 0.284444   \n",
      "36  0.000999    0.004998       0.433333                 0.187778   \n",
      "37  0.001002    0.004996       0.466667                 0.217778   \n",
      "38  0.001069    0.003949       0.500000                 0.250000   \n",
      "39  0.000977    0.005014       0.500000                 0.250000   \n",
      "40  0.005012    0.004988       0.833333                 0.845295   \n",
      "41  0.004997    0.004004       0.833333                 0.833333   \n",
      "42  0.002008    0.003993       0.833333                 0.849170   \n",
      "43  0.003996    0.004004       0.800000                 0.800000   \n",
      "44  0.002996    0.004004       0.700000                 0.700893   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.848214      SVM-poly-auto-1  \n",
      "26              0.800000          0.800000      0.850679      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.892857      SVM-poly-auto-1  \n",
      "28              0.733333          0.732143      0.760000      SVM-poly-auto-1  \n",
      "29              0.766667          0.760000      0.915556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.833333          0.830476      0.866071   SVM-linear-scale-2  \n",
      "41              0.833333          0.832381      0.814480   SVM-linear-scale-2  \n",
      "42              0.833333          0.832777      0.875000   SVM-linear-scale-2  \n",
      "43              0.800000          0.800000      0.853333   SVM-linear-scale-2  \n",
      "44              0.700000          0.699666      0.848889   SVM-linear-scale-2  \n",
      "SVM-poly-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      0.96      0.90        23\n",
      "      benign       0.96      0.85      0.90        27\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.90      0.90      0.90        50\n",
      "weighted avg       0.91      0.90      0.90        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "25  0.001996    0.004996       0.866667                 0.874405   \n",
      "26  0.002003    0.004002       0.800000                 0.800000   \n",
      "27  0.001000    0.004999       0.833333                 0.835556   \n",
      "28  0.001002    0.004998       0.733333                 0.737557   \n",
      "29  0.001001    0.005000       0.766667                 0.800000   \n",
      "30  0.000999    0.005002       0.533333                 0.284444   \n",
      "31  0.001000    0.005000       0.566667                 0.321111   \n",
      "32  0.001000    0.006000       0.466667                 0.217778   \n",
      "33  0.000999    0.005000       0.500000                 0.250000   \n",
      "34  0.001000    0.005004       0.500000                 0.250000   \n",
      "35  0.002002    0.004008       0.533333                 0.284444   \n",
      "36  0.000999    0.004998       0.433333                 0.187778   \n",
      "37  0.001002    0.004996       0.466667                 0.217778   \n",
      "38  0.001069    0.003949       0.500000                 0.250000   \n",
      "39  0.000977    0.005014       0.500000                 0.250000   \n",
      "40  0.005012    0.004988       0.833333                 0.845295   \n",
      "41  0.004997    0.004004       0.833333                 0.833333   \n",
      "42  0.002008    0.003993       0.833333                 0.849170   \n",
      "43  0.003996    0.004004       0.800000                 0.800000   \n",
      "44  0.002996    0.004004       0.700000                 0.700893   \n",
      "45  0.001017    0.004985       0.866667                 0.874405   \n",
      "46  0.002001    0.003999       0.833333                 0.851190   \n",
      "47  0.000999    0.005001       0.933333                 0.933333   \n",
      "48  0.002000    0.003999       0.833333                 0.834821   \n",
      "49  0.000999    0.003999       0.933333                 0.941176   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.848214      SVM-poly-auto-1  \n",
      "26              0.800000          0.800000      0.850679      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.892857      SVM-poly-auto-1  \n",
      "28              0.733333          0.732143      0.760000      SVM-poly-auto-1  \n",
      "29              0.766667          0.760000      0.915556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.833333          0.830476      0.866071   SVM-linear-scale-2  \n",
      "41              0.833333          0.832381      0.814480   SVM-linear-scale-2  \n",
      "42              0.833333          0.832777      0.875000   SVM-linear-scale-2  \n",
      "43              0.800000          0.800000      0.853333   SVM-linear-scale-2  \n",
      "44              0.700000          0.699666      0.848889   SVM-linear-scale-2  \n",
      "45              0.866667          0.866667      0.852679     SVM-poly-scale-2  \n",
      "46              0.833333          0.833890      0.850679     SVM-poly-scale-2  \n",
      "47              0.933333          0.933333      0.919643     SVM-poly-scale-2  \n",
      "48              0.833333          0.833148      0.880000     SVM-poly-scale-2  \n",
      "49              0.933333          0.933036      0.991111     SVM-poly-scale-2  \n",
      "SVM-rbf-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.88      1.00      0.94        23\n",
      "      benign       1.00      0.89      0.94        27\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.94      0.94      0.94        50\n",
      "weighted avg       0.95      0.94      0.94        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "25  0.001996    0.004996       0.866667                 0.874405   \n",
      "26  0.002003    0.004002       0.800000                 0.800000   \n",
      "27  0.001000    0.004999       0.833333                 0.835556   \n",
      "28  0.001002    0.004998       0.733333                 0.737557   \n",
      "29  0.001001    0.005000       0.766667                 0.800000   \n",
      "30  0.000999    0.005002       0.533333                 0.284444   \n",
      "31  0.001000    0.005000       0.566667                 0.321111   \n",
      "32  0.001000    0.006000       0.466667                 0.217778   \n",
      "33  0.000999    0.005000       0.500000                 0.250000   \n",
      "34  0.001000    0.005004       0.500000                 0.250000   \n",
      "35  0.002002    0.004008       0.533333                 0.284444   \n",
      "36  0.000999    0.004998       0.433333                 0.187778   \n",
      "37  0.001002    0.004996       0.466667                 0.217778   \n",
      "38  0.001069    0.003949       0.500000                 0.250000   \n",
      "39  0.000977    0.005014       0.500000                 0.250000   \n",
      "40  0.005012    0.004988       0.833333                 0.845295   \n",
      "41  0.004997    0.004004       0.833333                 0.833333   \n",
      "42  0.002008    0.003993       0.833333                 0.849170   \n",
      "43  0.003996    0.004004       0.800000                 0.800000   \n",
      "44  0.002996    0.004004       0.700000                 0.700893   \n",
      "45  0.001017    0.004985       0.866667                 0.874405   \n",
      "46  0.002001    0.003999       0.833333                 0.851190   \n",
      "47  0.000999    0.005001       0.933333                 0.933333   \n",
      "48  0.002000    0.003999       0.833333                 0.834821   \n",
      "49  0.000999    0.003999       0.933333                 0.941176   \n",
      "50  0.001001    0.005000       0.833333                 0.834087   \n",
      "51  0.001001    0.004999       0.833333                 0.836310   \n",
      "52  0.001000    0.005000       0.833333                 0.835556   \n",
      "53  0.000999    0.005001       0.800000                 0.805430   \n",
      "54  0.001000    0.005000       0.933333                 0.933333   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.848214      SVM-poly-auto-1  \n",
      "26              0.800000          0.800000      0.850679      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.892857      SVM-poly-auto-1  \n",
      "28              0.733333          0.732143      0.760000      SVM-poly-auto-1  \n",
      "29              0.766667          0.760000      0.915556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.833333          0.830476      0.866071   SVM-linear-scale-2  \n",
      "41              0.833333          0.832381      0.814480   SVM-linear-scale-2  \n",
      "42              0.833333          0.832777      0.875000   SVM-linear-scale-2  \n",
      "43              0.800000          0.800000      0.853333   SVM-linear-scale-2  \n",
      "44              0.700000          0.699666      0.848889   SVM-linear-scale-2  \n",
      "45              0.866667          0.866667      0.852679     SVM-poly-scale-2  \n",
      "46              0.833333          0.833890      0.850679     SVM-poly-scale-2  \n",
      "47              0.933333          0.933333      0.919643     SVM-poly-scale-2  \n",
      "48              0.833333          0.833148      0.880000     SVM-poly-scale-2  \n",
      "49              0.933333          0.933036      0.991111     SVM-poly-scale-2  \n",
      "50              0.833333          0.832772      0.892857      SVM-rbf-scale-2  \n",
      "51              0.833333          0.833895      0.927602      SVM-rbf-scale-2  \n",
      "52              0.833333          0.833519      0.915179      SVM-rbf-scale-2  \n",
      "53              0.800000          0.799107      0.911111      SVM-rbf-scale-2  \n",
      "54              0.933333          0.933333      0.982222      SVM-rbf-scale-2  \n",
      "SVM-sigmoid-scale-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.70      0.83      0.76        23\n",
      "      benign       0.83      0.70      0.76        27\n",
      "\n",
      "    accuracy                           0.76        50\n",
      "   macro avg       0.76      0.76      0.76        50\n",
      "weighted avg       0.77      0.76      0.76        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "5   0.002000    0.005001       0.900000                 0.902222   \n",
      "6   0.001011    0.004992       0.833333                 0.851190   \n",
      "7   0.001997    0.005007       0.933333                 0.933333   \n",
      "8   0.000994    0.005002       0.833333                 0.834821   \n",
      "9   0.000998    0.005003       0.900000                 0.901786   \n",
      "10  0.000999    0.006001       0.866667                 0.866667   \n",
      "11  0.000999    0.004003       0.800000                 0.800000   \n",
      "12  0.000998    0.006001       0.866667                 0.866667   \n",
      "13  0.001000    0.005000       0.800000                 0.805430   \n",
      "14  0.001000    0.004999       0.933333                 0.933333   \n",
      "15  0.001999    0.005012       0.566667                 0.563317   \n",
      "16  0.001988    0.008000       0.433333                 0.451852   \n",
      "17  0.001019    0.006029       0.500000                 0.518519   \n",
      "18  0.000955    0.005010       0.633333                 0.633929   \n",
      "19  0.000993    0.004992       0.633333                 0.638889   \n",
      "20  0.003998    0.005005       0.833333                 0.845295   \n",
      "21  0.003995    0.005005       0.833333                 0.833333   \n",
      "22  0.001994    0.005005       0.833333                 0.849170   \n",
      "23  0.003996    0.004004       0.800000                 0.800000   \n",
      "24  0.003997    0.004003       0.700000                 0.700893   \n",
      "25  0.001996    0.004996       0.866667                 0.874405   \n",
      "26  0.002003    0.004002       0.800000                 0.800000   \n",
      "27  0.001000    0.004999       0.833333                 0.835556   \n",
      "28  0.001002    0.004998       0.733333                 0.737557   \n",
      "29  0.001001    0.005000       0.766667                 0.800000   \n",
      "30  0.000999    0.005002       0.533333                 0.284444   \n",
      "31  0.001000    0.005000       0.566667                 0.321111   \n",
      "32  0.001000    0.006000       0.466667                 0.217778   \n",
      "33  0.000999    0.005000       0.500000                 0.250000   \n",
      "34  0.001000    0.005004       0.500000                 0.250000   \n",
      "35  0.002002    0.004008       0.533333                 0.284444   \n",
      "36  0.000999    0.004998       0.433333                 0.187778   \n",
      "37  0.001002    0.004996       0.466667                 0.217778   \n",
      "38  0.001069    0.003949       0.500000                 0.250000   \n",
      "39  0.000977    0.005014       0.500000                 0.250000   \n",
      "40  0.005012    0.004988       0.833333                 0.845295   \n",
      "41  0.004997    0.004004       0.833333                 0.833333   \n",
      "42  0.002008    0.003993       0.833333                 0.849170   \n",
      "43  0.003996    0.004004       0.800000                 0.800000   \n",
      "44  0.002996    0.004004       0.700000                 0.700893   \n",
      "45  0.001017    0.004985       0.866667                 0.874405   \n",
      "46  0.002001    0.003999       0.833333                 0.851190   \n",
      "47  0.000999    0.005001       0.933333                 0.933333   \n",
      "48  0.002000    0.003999       0.833333                 0.834821   \n",
      "49  0.000999    0.003999       0.933333                 0.941176   \n",
      "50  0.001001    0.005000       0.833333                 0.834087   \n",
      "51  0.001001    0.004999       0.833333                 0.836310   \n",
      "52  0.001000    0.005000       0.833333                 0.835556   \n",
      "53  0.000999    0.005001       0.800000                 0.805430   \n",
      "54  0.001000    0.005000       0.933333                 0.933333   \n",
      "55  0.002001    0.004000       0.600000                 0.598148   \n",
      "56  0.001001    0.005017       0.833333                 0.843333   \n",
      "57  0.000000    0.004998       0.866667                 0.874405   \n",
      "58  0.001001    0.003999       0.633333                 0.633929   \n",
      "59  0.001000    0.006000       0.633333                 0.638889   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc                model  \n",
      "0               0.833333          0.830476      0.866071   SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480   SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000   SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333   SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889   SVM-linear-scale-1  \n",
      "5               0.900000          0.900111      0.852679     SVM-poly-scale-1  \n",
      "6               0.833333          0.833890      0.837104     SVM-poly-scale-1  \n",
      "7               0.933333          0.933333      0.924107     SVM-poly-scale-1  \n",
      "8               0.833333          0.833148      0.871111     SVM-poly-scale-1  \n",
      "9               0.900000          0.899889      0.982222     SVM-poly-scale-1  \n",
      "10              0.866667          0.866667      0.910714      SVM-rbf-scale-1  \n",
      "11              0.800000          0.800000      0.918552      SVM-rbf-scale-1  \n",
      "12              0.866667          0.866667      0.919643      SVM-rbf-scale-1  \n",
      "13              0.800000          0.799107      0.902222      SVM-rbf-scale-1  \n",
      "14              0.933333          0.933333      0.986667      SVM-rbf-scale-1  \n",
      "15              0.566667          0.559238      0.598214  SVM-sigmoid-scale-1  \n",
      "16              0.433333          0.430182      0.393665  SVM-sigmoid-scale-1  \n",
      "17              0.500000          0.480000      0.397321  SVM-sigmoid-scale-1  \n",
      "18              0.633333          0.632925      0.671111  SVM-sigmoid-scale-1  \n",
      "19              0.633333          0.629630      0.640000  SVM-sigmoid-scale-1  \n",
      "20              0.833333          0.830476      0.866071    SVM-linear-auto-1  \n",
      "21              0.833333          0.832381      0.814480    SVM-linear-auto-1  \n",
      "22              0.833333          0.832777      0.875000    SVM-linear-auto-1  \n",
      "23              0.800000          0.800000      0.853333    SVM-linear-auto-1  \n",
      "24              0.700000          0.699666      0.848889    SVM-linear-auto-1  \n",
      "25              0.866667          0.866667      0.848214      SVM-poly-auto-1  \n",
      "26              0.800000          0.800000      0.850679      SVM-poly-auto-1  \n",
      "27              0.833333          0.833519      0.892857      SVM-poly-auto-1  \n",
      "28              0.733333          0.732143      0.760000      SVM-poly-auto-1  \n",
      "29              0.766667          0.760000      0.915556      SVM-poly-auto-1  \n",
      "30              0.533333          0.371014      0.593750       SVM-rbf-auto-1  \n",
      "31              0.566667          0.409929      0.558824       SVM-rbf-auto-1  \n",
      "32              0.466667          0.296970      0.531250       SVM-rbf-auto-1  \n",
      "33              0.500000          0.333333      0.566667       SVM-rbf-auto-1  \n",
      "34              0.500000          0.333333      0.500000       SVM-rbf-auto-1  \n",
      "35              0.533333          0.371014      0.500000   SVM-sigmoid-auto-1  \n",
      "36              0.433333          0.262016      0.500000   SVM-sigmoid-auto-1  \n",
      "37              0.466667          0.296970      0.500000   SVM-sigmoid-auto-1  \n",
      "38              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "39              0.500000          0.333333      0.500000   SVM-sigmoid-auto-1  \n",
      "40              0.833333          0.830476      0.866071   SVM-linear-scale-2  \n",
      "41              0.833333          0.832381      0.814480   SVM-linear-scale-2  \n",
      "42              0.833333          0.832777      0.875000   SVM-linear-scale-2  \n",
      "43              0.800000          0.800000      0.853333   SVM-linear-scale-2  \n",
      "44              0.700000          0.699666      0.848889   SVM-linear-scale-2  \n",
      "45              0.866667          0.866667      0.852679     SVM-poly-scale-2  \n",
      "46              0.833333          0.833890      0.850679     SVM-poly-scale-2  \n",
      "47              0.933333          0.933333      0.919643     SVM-poly-scale-2  \n",
      "48              0.833333          0.833148      0.880000     SVM-poly-scale-2  \n",
      "49              0.933333          0.933036      0.991111     SVM-poly-scale-2  \n",
      "50              0.833333          0.832772      0.892857      SVM-rbf-scale-2  \n",
      "51              0.833333          0.833895      0.927602      SVM-rbf-scale-2  \n",
      "52              0.833333          0.833519      0.915179      SVM-rbf-scale-2  \n",
      "53              0.800000          0.799107      0.911111      SVM-rbf-scale-2  \n",
      "54              0.933333          0.933333      0.982222      SVM-rbf-scale-2  \n",
      "55              0.600000          0.596380      0.571429  SVM-sigmoid-scale-2  \n",
      "56              0.833333          0.829221      0.769231  SVM-sigmoid-scale-2  \n",
      "57              0.866667          0.866667      0.901786  SVM-sigmoid-scale-2  \n",
      "58              0.633333          0.632925      0.648889  SVM-sigmoid-scale-2  \n",
      "59              0.633333          0.629630      0.622222  SVM-sigmoid-scale-2  \n",
      "SVM-linear-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.78      0.91      0.84        23\n",
      "      benign       0.91      0.78      0.84        27\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.85      0.85      0.84        50\n",
      "weighted avg       0.85      0.84      0.84        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "..       ...         ...            ...                      ...   \n",
      "60  0.004998    0.005003       0.833333                 0.845295   \n",
      "61  0.003996    0.005003       0.833333                 0.833333   \n",
      "62  0.001997    0.004003       0.833333                 0.849170   \n",
      "63  0.003997    0.004003       0.800000                 0.800000   \n",
      "64  0.003056    0.003979       0.700000                 0.700893   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.833333          0.830476      0.866071  SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480  SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000  SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333  SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "60              0.833333          0.830476      0.866071   SVM-linear-auto-2  \n",
      "61              0.833333          0.832381      0.814480   SVM-linear-auto-2  \n",
      "62              0.833333          0.832777      0.875000   SVM-linear-auto-2  \n",
      "63              0.800000          0.800000      0.853333   SVM-linear-auto-2  \n",
      "64              0.700000          0.699666      0.848889   SVM-linear-auto-2  \n",
      "\n",
      "[65 rows x 8 columns]\n",
      "SVM-poly-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.84      0.91      0.88        23\n",
      "      benign       0.92      0.85      0.88        27\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.88      0.88        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "..       ...         ...            ...                      ...   \n",
      "65  0.001000    0.005000       0.866667                 0.874405   \n",
      "66  0.001000    0.005001       0.800000                 0.800000   \n",
      "67  0.001000    0.004000       0.833333                 0.835556   \n",
      "68  0.001000    0.005000       0.733333                 0.737557   \n",
      "69  0.001000    0.004000       0.766667                 0.800000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.833333          0.830476      0.866071  SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480  SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000  SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333  SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "65              0.866667          0.866667      0.848214     SVM-poly-auto-2  \n",
      "66              0.800000          0.800000      0.850679     SVM-poly-auto-2  \n",
      "67              0.833333          0.833519      0.892857     SVM-poly-auto-2  \n",
      "68              0.733333          0.732143      0.760000     SVM-poly-auto-2  \n",
      "69              0.766667          0.760000      0.915556     SVM-poly-auto-2  \n",
      "\n",
      "[70 rows x 8 columns]\n",
      "SVM-rbf-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.47      1.00      0.64        23\n",
      "      benign       1.00      0.04      0.07        27\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.73      0.52      0.36        50\n",
      "weighted avg       0.76      0.48      0.33        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "..       ...         ...            ...                      ...   \n",
      "70  0.001056    0.004944       0.533333                 0.284444   \n",
      "71  0.001000    0.004993       0.566667                 0.321111   \n",
      "72  0.001007    0.005007       0.466667                 0.217778   \n",
      "73  0.001001    0.005992       0.500000                 0.250000   \n",
      "74  0.001007    0.004002       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.833333          0.830476      0.866071  SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480  SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000  SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333  SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "70              0.533333          0.371014      0.593750      SVM-rbf-auto-2  \n",
      "71              0.566667          0.409929      0.558824      SVM-rbf-auto-2  \n",
      "72              0.466667          0.296970      0.531250      SVM-rbf-auto-2  \n",
      "73              0.500000          0.333333      0.566667      SVM-rbf-auto-2  \n",
      "74              0.500000          0.333333      0.500000      SVM-rbf-auto-2  \n",
      "\n",
      "[75 rows x 8 columns]\n",
      "SVM-sigmoid-auto-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.46      1.00      0.63        23\n",
      "      benign       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.23      0.50      0.32        50\n",
      "weighted avg       0.21      0.46      0.29        50\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.004999    0.005002       0.833333                 0.845295   \n",
      "1   0.004997    0.005004       0.833333                 0.833333   \n",
      "2   0.001997    0.005002       0.833333                 0.849170   \n",
      "3   0.003997    0.004003       0.800000                 0.800000   \n",
      "4   0.004001    0.008000       0.700000                 0.700893   \n",
      "..       ...         ...            ...                      ...   \n",
      "75  0.000000    0.004999       0.533333                 0.284444   \n",
      "76  0.001000    0.004021       0.433333                 0.187778   \n",
      "77  0.000979    0.003999       0.466667                 0.217778   \n",
      "78  0.000995    0.003999       0.500000                 0.250000   \n",
      "79  0.000999    0.005000       0.500000                 0.250000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc               model  \n",
      "0               0.833333          0.830476      0.866071  SVM-linear-scale-1  \n",
      "1               0.833333          0.832381      0.814480  SVM-linear-scale-1  \n",
      "2               0.833333          0.832777      0.875000  SVM-linear-scale-1  \n",
      "3               0.800000          0.800000      0.853333  SVM-linear-scale-1  \n",
      "4               0.700000          0.699666      0.848889  SVM-linear-scale-1  \n",
      "..                   ...               ...           ...                 ...  \n",
      "75              0.533333          0.371014      0.500000  SVM-sigmoid-auto-2  \n",
      "76              0.433333          0.262016      0.500000  SVM-sigmoid-auto-2  \n",
      "77              0.466667          0.296970      0.500000  SVM-sigmoid-auto-2  \n",
      "78              0.500000          0.333333      0.500000  SVM-sigmoid-auto-2  \n",
      "79              0.500000          0.333333      0.500000  SVM-sigmoid-auto-2  \n",
      "\n",
      "[80 rows x 8 columns]\n",
      "9.568008300033398\n"
     ]
    }
   ],
   "source": [
    "## S0: All Combined \n",
    " \n",
    "df_malicious = pd.concat([df1,df2,df3,df4,df5,df6,df7,df32,df33,df34,df35])[:1000]\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df11,df10,df12,df13,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df30,df27,df29])[:1000]\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious: 1217322\n",
      "benign: 1212624\n",
      "0 NAN in malicious!\n",
      "28 NAN in benign!\n",
      "After droppping NAN rows: \n",
      "malicious: 1217322\n",
      "benign: 1212596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [13:47<00:00, 20.69s/it]  \n",
      "Feature Extraction: 100%|██████████| 40/40 [16:16<00:00, 24.42s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n"
     ]
    }
   ],
   "source": [
    "#scenario 1 :Devices\n",
    "# 1) Server\n",
    " \n",
    "df_malicious = pd.concat([df2,df7,df32])\n",
    "df_benign = pd.concat([df10,df11,df13,df15,df16,df17,df18,df19,df21,df22,df23,df26,df30,df28])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_server_s1 = run_process(df_malicious,df_benign)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " #2) Laptop\n",
    "df_malicious = pd.concat([df35])\n",
    "df_benign = pd.concat([df8,df20,df19,df30])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Laptop_s1 = run_process(df_malicious,df_benign)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3) IoT\n",
    "\n",
    "df_malicious = pd.concat([df4,df5,df6,df33,df34])\n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df15,df16,df17,df21])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Raspberry_s1 = run_process(df_malicious,df_benign)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scenario 2; Throttles\n",
    "    \n",
    "    # 1) THR: %10 (Stealthy)\n",
    "\n",
    "df_malicious = pd.concat([df33])\n",
    "df_benign = pd.concat([df8,df10])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_10_s2 = run_process(df_malicious,df_benign)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2) THR: %50 (Robust)\n",
    "\n",
    "df_malicious = pd.concat([df3,df34])\n",
    "df_benign = pd.concat([df29,df31])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_50_s2 = run_process(df_malicious,df_benign)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # 3) THR: %100 (Aggressive)\n",
    "    \n",
    "df_malicious = pd.concat([df1,df2,df4,df5,df6,df7,df35])\n",
    "df_benign    = pd.concat([df11,df12,df13,df14,df16,df17,df21,df23,df26,df27,df28,df29,df30,df31])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_THR_100_s2 = run_process(df_malicious,df_benign)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## S3; In-browser VS Binary ##\n",
    "\n",
    "  #1) In-Browser\n",
    "df_malicious = pd.concat([df3,df5,df6,df7,df32,df33,df34,df35])\n",
    "df_benign = pd.concat([df8,df9,df14,df15,df16,df17,df18,df19,df20,df14])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_In_s3 = run_process(df_malicious,df_benign)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Binary\n",
    "df_malicious = pd.concat([df1,df2,df4])\n",
    "df_benign = pd.concat([df12,df13,df15,df17,df22,df23,df27,df28,df29])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_Host_s3 = run_process(df_malicious,df_benign)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## S4: Fully compromised (All)\n",
    " \n",
    "df_malicious = pd.concat([df1,df2,df3,df4,df5,df6,df7,df32,df33,df34,df35])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df11,df10,df12,df13,df15,df16,df17,df18,df19,df20,df21,df22,df23,df24,df25,df30,df27,df29])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## S5: Partially compromised (IoT + Laptop)\n",
    " \n",
    "df_malicious = pd.concat([df5,df35])\n",
    " \n",
    "df_benign = pd.concat([df14,df16,df18,df19,df20])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## S6: Single compromised (IoT) (Raspberry)\n",
    " \n",
    "df_malicious = pd.concat([df5])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10])\n",
    "\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## S7: IoT compromised (IoT + IoT)\n",
    " \n",
    "df_malicious = pd.concat([df1,df34])\n",
    " \n",
    "df_benign = pd.concat([df8,df9,df10,df11,df12,df21])\n",
    "\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious = df_malicious.dropna()\n",
    "df_benign = df_benign.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "print(\"malicious: {}\".format(len(df_malicious)))\n",
    "print(\"benign: {}\".format(len(df_benign)))\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious,df_benign)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
