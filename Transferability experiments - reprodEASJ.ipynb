{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tsfresh\n",
    "import os\n",
    "import json\n",
    "import scapy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #ignore warnings caused by \n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               malicious csv files import                      #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1 = pd.read_csv(r\".\\malicious\\WebOS_binary.csv\") #\n",
    "df2 = pd.read_csv(r\".\\malicious\\Server_Binary.csv\") #\n",
    "df3 = pd.read_csv(r\".\\malicious\\Raspberry_Webmine_Robust.csv\")\n",
    "df4 = pd.read_csv(r\".\\malicious\\Raspberry_Binary.csv\") #\n",
    "df5 = pd.read_csv(r\".\\malicious\\Raspberry_Webmine_Aggressive.csv\")\n",
    "df6 = pd.read_csv(r\".\\malicious\\Raspberry_WebminePool_Aggressive.csv\")\n",
    "df7 = pd.read_csv(r\".\\malicious\\Server_WebminePool_Aggressive.csv\") #\n",
    "\n",
    "df32 = pd.read_csv(r\".\\malicious\\Server_WebminePool_Robust.csv\") #\n",
    "df33 = pd.read_csv(r\".\\malicious\\Raspberry_WebminePool_Stealthy.csv\") #\n",
    "df34 = pd.read_csv(r\".\\malicious\\Raspberry_WebminePool_Robust.csv\") #\n",
    "df35 = pd.read_csv(r\".\\malicious\\Desktop_WebminePool_Aggressive.csv\") #\n",
    "\n",
    "\n",
    "#################################################################\n",
    "#                                                               #\n",
    "#               benign csv files import                         #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "############### LAPTOP #############\n",
    "\n",
    "df8 = pd.read_csv(r\".\\benign-2\\Laptop\\Laptop_download_benign.csv\")\n",
    "df9 = pd.read_csv(r\".\\benign-2\\Laptop\\Laptop_idle_benign.csv\")\n",
    "df10 = pd.read_csv(r\".\\benign-2\\Laptop\\Laptop_interactive_benign.csv\")\n",
    "df11 = pd.read_csv(r\".\\benign-2\\Laptop\\Laptop_video_benign.csv\")\n",
    "df12 = pd.read_csv(r\".\\benign-2\\Laptop\\Laptop_webbrowsing_benign.csv\")\n",
    "\n",
    "############### Raspberry ##########\n",
    "\n",
    "df13 = pd.read_csv(r\".\\benign-2\\Raspberry\\Raspberry_download_benign.csv\")\n",
    "df14 = pd.read_csv(r\".\\benign-2\\Raspberry\\Raspberry_idle_benign.csv\")\n",
    "df15 = pd.read_csv(r\".\\benign-2\\Raspberry\\Raspberry_interactive_benign.csv\")\n",
    "df16 = pd.read_csv(r\".\\benign-2\\Raspberry\\Raspberry_video_benign.csv\")\n",
    "df17 = pd.read_csv(r\".\\benign-2\\Raspberry\\Raspberry_webbrowsing_benign.csv\")\n",
    "\n",
    "############### Server ############\n",
    "\n",
    "\n",
    "df18 = pd.read_csv(r\".\\benign-2\\Server\\Server_download_benign.csv\")\n",
    "df19 = pd.read_csv(r\".\\benign-2\\Server\\Server_idle_benign.csv\")\n",
    "df20 = pd.read_csv(r\".\\benign-2\\Server\\Server_interactive_benign.csv\")\n",
    "df21 = pd.read_csv(r\".\\benign-2\\Server\\Server_video_benign.csv\")\n",
    "df22 = pd.read_csv(r\".\\benign-2\\Server\\Server_webbrowsing_benign.csv\")\n",
    "\n",
    "############### WebOS ############\n",
    "\n",
    "df23 = pd.read_csv(r\".\\benign-2\\WebOS\\Webos_video(live&normal)_benign.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 -->> 43173\n",
      "df2 -->> 1213354\n",
      "df3 -->> 3621\n",
      "df4 -->> 22111\n",
      "df5 -->> 14156\n",
      "df6 -->> 24476\n",
      "df7 -->> 3106\n",
      "df32 -->> 18460\n",
      "df33 -->> 10285\n",
      "df34 -->> 7708\n",
      "df35 -->> 234892\n",
      "/////////////////////////////////////////////////\n",
      " LAPTOP \n",
      "df8 -->> 442866\n",
      "df9 -->> 113602\n",
      "df10 -->> 81681\n",
      "df11 -->> 29010\n",
      "df12 -->> 99235\n",
      " Raspberry \n",
      "df13 -->> 276808\n",
      "df14 -->> 73\n",
      "df15 -->> 104241\n",
      "df16 -->> 57205\n",
      "df17 -->> 123298\n",
      " Server \n",
      "df18 -->> 564831\n",
      "df19 -->> 13459\n",
      "df20 -->> 123728\n",
      "df21 -->> 109497\n",
      "df22 -->> 43713\n",
      " WebOS \n",
      "df23 -->> 177704\n"
     ]
    }
   ],
   "source": [
    "print(\"df1 -->> {}\".format(len(df1)))\n",
    "print(\"df2 -->> {}\".format(len(df2)))\n",
    "print(\"df3 -->> {}\".format(len(df3)))\n",
    "print(\"df4 -->> {}\".format(len(df4)))\n",
    "print(\"df5 -->> {}\".format(len(df5)))\n",
    "print(\"df6 -->> {}\".format(len(df6)))\n",
    "print(\"df7 -->> {}\".format(len(df7)))\n",
    "print(\"df32 -->> {}\".format(len(df32)))\n",
    "print(\"df33 -->> {}\".format(len(df33)))\n",
    "print(\"df34 -->> {}\".format(len(df34)))\n",
    "print(\"df35 -->> {}\".format(len(df35)))\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "print(\" LAPTOP \")\n",
    "\n",
    "\n",
    "print(\"df8 -->> {}\".format(len(df8)))\n",
    "print(\"df9 -->> {}\".format(len(df9)))\n",
    "print(\"df10 -->> {}\".format(len(df10)))\n",
    "print(\"df11 -->> {}\".format(len(df11)))\n",
    "print(\"df12 -->> {}\".format(len(df12)))\n",
    "\n",
    "print(\" Raspberry \")\n",
    "\n",
    "\n",
    "print(\"df13 -->> {}\".format(len(df13)))\n",
    "print(\"df14 -->> {}\".format(len(df14)))\n",
    "print(\"df15 -->> {}\".format(len(df15)))\n",
    "print(\"df16 -->> {}\".format(len(df16)))\n",
    "print(\"df17 -->> {}\".format(len(df17)))\n",
    "\n",
    "print(\" Server \")\n",
    "\n",
    "print(\"df18 -->> {}\".format(len(df18)))\n",
    "print(\"df19 -->> {}\".format(len(df19)))\n",
    "print(\"df20 -->> {}\".format(len(df20)))\n",
    "print(\"df21 -->> {}\".format(len(df21)))\n",
    "print(\"df22 -->> {}\".format(len(df22)))\n",
    "\n",
    "print(\" WebOS \")\n",
    "\n",
    "print(\"df23 -->> {}\".format(len(df23)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune the datasets for labeling process for malicious data\n",
    "\n",
    "\n",
    "# For WebOS = 18:56:80:17:d0:ef\n",
    "index_names = df1[((df1['HW_dst'] != '18:56:80:17:d0:ef') & (df1['Hw_src'] != '18:56:80:17:d0:ef'))].index\n",
    "df1.drop(index_names, inplace = True)\n",
    "\n",
    "# Big_Server_Monero_mining_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df2[((df2['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df2['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df2.drop(index_names, inplace = True)\n",
    "\n",
    "# ege_data_rasberry = dc:a6:32:67:66:4b\t\n",
    "\n",
    "index_names = df3[((df3['HW_dst'] != 'dc:a6:32:67:66:4b') & (df3['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df3.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_binary_monero_mining = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df4[((df4['HW_dst'] != 'dc:a6:32:68:35:8a') & (df4['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df4.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_network_data_2 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df5[((df5['HW_dst'] != 'dc:a6:32:67:66:4b') & (df5['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df5.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry-Webmine = dc:a6:32:67:66:4b\n",
    "index_names = df6[((df6['HW_dst'] != 'dc:a6:32:67:66:4b') & (df6['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df6.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_Webmine_Network_data = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df7[((df7['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df7['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df7.drop(index_names, inplace = True)\n",
    "\n",
    "# Server_%50_Mining = a4:bb:6d:ac:e1:fd\n",
    "\n",
    "index_names = df32[((df32['HW_dst'] != 'a4:bb:6d:ac:e1:fd') & (df32['Hw_src'] != 'a4:bb:6d:ac:e1:fd'))].index\n",
    "df32.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%10 = dc:a6:32:67:66:4b\n",
    "\n",
    "index_names = df33[((df33['HW_dst'] != 'dc:a6:32:67:66:4b') & (df33['Hw_src'] != 'dc:a6:32:67:66:4b'))].index\n",
    "df33.drop(index_names, inplace = True)\n",
    "\n",
    "# Rasberry_webmine_%50 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df34[((df34['HW_dst'] != 'dc:a6:32:68:35:8a') & (df34['Hw_src'] != 'dc:a6:32:68:35:8a'))].index\n",
    "df34.drop(index_names, inplace = True)\n",
    "\n",
    "# Desktop_Webmine_%100 = dc:a6:32:68:35:8a\n",
    "\n",
    "index_names = df35[((df35['HW_dst'] != 'd8:3b:bf:8f:ba:ba') & (df35['Hw_src'] != 'd8:3b:bf:8f:ba:ba'))].index\n",
    "df35.drop(index_names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#                                                               #\n",
    "#      Labeling Features for further calculations               #\n",
    "#                                                               #\n",
    "#################################################################\n",
    "\n",
    "df1.insert(7, \"Is_malicious\", 1)\n",
    "df2.insert(7, \"Is_malicious\", 1)\n",
    "df3.insert(7, \"Is_malicious\", 1)\n",
    "df4.insert(7, \"Is_malicious\", 1)\n",
    "df5.insert(7, \"Is_malicious\", 1)\n",
    "df6.insert(7, \"Is_malicious\", 1)\n",
    "df7.insert(7, \"Is_malicious\", 1)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "df8.insert(7, \"Is_malicious\", 0)\n",
    "df9.insert(7, \"Is_malicious\", 0)\n",
    "df10.insert(7, \"Is_malicious\", 0)\n",
    "df11.insert(7, \"Is_malicious\", 0)\n",
    "df12.insert(7, \"Is_malicious\", 0)\n",
    "df13.insert(7, \"Is_malicious\", 0)\n",
    "df14.insert(7, \"Is_malicious\", 0)\n",
    "df15.insert(7, \"Is_malicious\", 0)\n",
    "df16.insert(7, \"Is_malicious\", 0)\n",
    "df17.insert(7, \"Is_malicious\", 0)\n",
    "df18.insert(7, \"Is_malicious\", 0)\n",
    "df19.insert(7, \"Is_malicious\", 0)\n",
    "df20.insert(7, \"Is_malicious\", 0)\n",
    "df21.insert(7, \"Is_malicious\", 0)\n",
    "df22.insert(7, \"Is_malicious\", 0)\n",
    "df23.insert(7, \"Is_malicious\", 0)\n",
    "\n",
    "# ========================================================\n",
    "\n",
    "\n",
    "df32.insert(7, \"Is_malicious\", 1)\n",
    "df33.insert(7, \"Is_malicious\", 1)\n",
    "df34.insert(7, \"Is_malicious\", 1)\n",
    "df35.insert(7, \"Is_malicious\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_process(a,b,c,d):\n",
    "    #run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test,df_results)\n",
    " \n",
    "  \n",
    "    df_malicious_Train = a.copy()\n",
    "    df_benign_Train    = b.copy()\n",
    "    \n",
    "    df_malicious_Test = c.copy()\n",
    "    df_benign_Test    = d.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    from tsfresh import extract_features, select_features\n",
    "    from tsfresh.utilities.dataframe_functions import impute\n",
    "    from tsfresh import extract_features\n",
    "    from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "\n",
    "\n",
    "    df_malicious_Train.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious_Train['id']= np.floor(df_malicious_Train.index.array/10)\n",
    "    \n",
    "    df_malicious_Test.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_malicious_Test['id']= np.floor(df_malicious_Test.index.array/10)\n",
    "    \n",
    "    \n",
    "    df_benign_Train.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign_Train['id']= np.floor(df_benign_Train.index.array/10)\n",
    "    \n",
    "    df_benign_Test.reset_index(drop=True, inplace=True) #reset index\n",
    "    df_benign_Test['id']= np.floor(df_benign_Test.index.array/10)\n",
    "    \n",
    "\n",
    "\n",
    "    tf1=tsfresh.extract_features(df_malicious_Train,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1['class']= 1\n",
    "    \n",
    "    tf1_1=tsfresh.extract_features(df_malicious_Test,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf1_1['class']= 1\n",
    "\n",
    "      \n",
    "    tf2=tsfresh.extract_features(df_benign_Train,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2['class']= 0\n",
    "    \n",
    "    tf2_1=tsfresh.extract_features(df_benign_Test,impute_function=impute, column_kind='Is_malicious',\n",
    "                                 column_id='id',column_sort=\"Time\",column_value = \"Length\")\n",
    "    tf2_1['class']= 0\n",
    "    \n",
    "\n",
    "    tf2.columns = tf1.columns\n",
    "    tf2_1.columns = tf1_1.columns\n",
    "    \n",
    "\n",
    "    features_train=pd.concat([tf1,tf2])\n",
    "    features_test=pd.concat([tf1_1,tf2_1])\n",
    "    \n",
    "    \n",
    "    features2_train = features_train.copy()\n",
    "    features2_train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_train = pd.Series(data = features2_train['class'], index=features2_train.index)\n",
    "    \n",
    "    relevance_table_train = calculate_relevance_table(features2_train, y_train)\n",
    "    \n",
    "\n",
    "    relevance_table_train = relevance_table_train[relevance_table_train.relevant]\n",
    "    relevance_table_train.sort_values(\"p_value\", inplace=True)\n",
    "    best_features_train = relevance_table_train[relevance_table_train['p_value'] <= 0.05] \n",
    "    \n",
    "    \n",
    "    df_ML_train = pd.DataFrame()\n",
    "    df_ML_test  = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    df_ML_train[best_features_train.feature] = features_train[best_features_train.feature]\n",
    "\n",
    "    df_ML_test[best_features_train.feature] = features_test[best_features_train.feature]\n",
    "\n",
    "\n",
    "    final = ML_Process(df_ML_train,df_ML_test)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_Process(df_ML_train,df_ML_test):\n",
    "    #df_results = x.copy() \n",
    "    print('let the ml starts')\n",
    "  \n",
    "    from sklearn import neighbors, metrics\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "\n",
    "    X_train = df_ML_train.drop('class',axis=1).to_numpy()\n",
    "    y_train = df_ML_train['class'].to_numpy()\n",
    "\n",
    "    X_test = df_ML_test.drop('class',axis=1).to_numpy()\n",
    "    y_test = df_ML_test['class'].to_numpy()\n",
    "\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    Le = LabelEncoder()\n",
    "    for i in range(len(X_train[0])):\n",
    "        X_train[:, i] = Le.fit_transform(X_train[:, i])\n",
    "    for i in range(len(X_train[0])):\n",
    "        X_test[:, i] = Le.fit_transform(X_test[:, i])\n",
    "\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8675309)\n",
    "\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    #from xgboost import XGBClassifier\n",
    "    from sklearn import model_selection\n",
    "    from sklearn.utils import class_weight\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    y_train = y_train.ravel()\n",
    "    dfs = []\n",
    "    models = [\n",
    "          ('LogReg', LogisticRegression()), \n",
    "          #('RF', RandomForestClassifier()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('SVM', SVC()), \n",
    "          ('GNB', GaussianNB())\n",
    "          #('XGB', XGBClassifier())\n",
    "            ]\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "    target_names = ['malignant', 'benign']\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, \n",
    "                                                    scoring=scoring)\n",
    "\n",
    "        clf = model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        #df_resulta = df_results.append(dfs)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        print(final)\n",
    "\n",
    "\n",
    "    return(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 12871\n",
      "malicious_test: 19643\n",
      "benign_train: 450000\n",
      "benign_test: 111625\n",
      "After droppping NAN rows: \n",
      "malicious_train: 12871\n",
      "malicious_test: 19643\n",
      "benign_train: 450000\n",
      "benign_test: 111625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:09<00:00,  4.22it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:13<00:00,  2.92it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [04:54<00:00,  7.37s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [01:10<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.96      0.99      0.97     11163\n",
      "      benign       0.95      0.74      0.83      1965\n",
      "\n",
      "    accuracy                           0.96     13128\n",
      "   macro avg       0.95      0.87      0.90     13128\n",
      "weighted avg       0.96      0.96      0.95     13128\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.725244    0.013000       0.992871                 0.992652   \n",
      "1  0.754731    0.015001       0.991791                 0.991581   \n",
      "2  0.693568    0.011997       0.993735                 0.993570   \n",
      "3  0.717081    0.012996       0.993410                 0.993215   \n",
      "4  0.708147    0.011003       0.992870                 0.992675   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.992871          0.992684      0.991673  LogReg  \n",
      "1              0.991791          0.991661      0.981386  LogReg  \n",
      "2              0.993735          0.993493      0.990244  LogReg  \n",
      "3              0.993410          0.993247      0.990036  LogReg  \n",
      "4              0.992870          0.992738      0.984070  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.98      0.95     11163\n",
      "      benign       0.81      0.59      0.68      1965\n",
      "\n",
      "    accuracy                           0.92     13128\n",
      "   macro avg       0.87      0.78      0.82     13128\n",
      "weighted avg       0.91      0.92      0.91     13128\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.725244    0.013000       0.992871                 0.992652   \n",
      "1  0.754731    0.015001       0.991791                 0.991581   \n",
      "2  0.693568    0.011997       0.993735                 0.993570   \n",
      "3  0.717081    0.012996       0.993410                 0.993215   \n",
      "4  0.708147    0.011003       0.992870                 0.992675   \n",
      "5  0.051004    3.418969       0.986714                 0.985859   \n",
      "6  0.055000    1.441328       0.985526                 0.984614   \n",
      "7  0.053998    1.373265       0.987146                 0.986242   \n",
      "8  0.049005    1.411993       0.985632                 0.984768   \n",
      "9  0.047046    1.391654       0.987037                 0.986186   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.992871          0.992684      0.991673  LogReg  \n",
      "1              0.991791          0.991661      0.981386  LogReg  \n",
      "2              0.993735          0.993493      0.990244  LogReg  \n",
      "3              0.993410          0.993247      0.990036  LogReg  \n",
      "4              0.992870          0.992738      0.984070  LogReg  \n",
      "5              0.986714          0.986020      0.958965     KNN  \n",
      "6              0.985526          0.984921      0.932783     KNN  \n",
      "7              0.987146          0.986146      0.948712     KNN  \n",
      "8              0.985632          0.985061      0.945536     KNN  \n",
      "9              0.987037          0.986416      0.945523     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.89      0.93     11163\n",
      "      benign       0.58      0.89      0.71      1965\n",
      "\n",
      "    accuracy                           0.89     13128\n",
      "   macro avg       0.78      0.89      0.82     13128\n",
      "weighted avg       0.92      0.89      0.90     13128\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.725244    0.013000       0.992871                 0.992652   \n",
      "1   0.754731    0.015001       0.991791                 0.991581   \n",
      "2   0.693568    0.011997       0.993735                 0.993570   \n",
      "3   0.717081    0.012996       0.993410                 0.993215   \n",
      "4   0.708147    0.011003       0.992870                 0.992675   \n",
      "5   0.051004    3.418969       0.986714                 0.985859   \n",
      "6   0.055000    1.441328       0.985526                 0.984614   \n",
      "7   0.053998    1.373265       0.987146                 0.986242   \n",
      "8   0.049005    1.411993       0.985632                 0.984768   \n",
      "9   0.047046    1.391654       0.987037                 0.986186   \n",
      "10  7.706005    4.359030       0.986822                 0.986149   \n",
      "11  7.529908    4.257102       0.987146                 0.986347   \n",
      "12  7.834819    4.351607       0.987038                 0.986252   \n",
      "13  7.962861    4.299286       0.987469                 0.986612   \n",
      "14  7.649261    4.323349       0.988657                 0.988005   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.992871          0.992684      0.991673  LogReg  \n",
      "1               0.991791          0.991661      0.981386  LogReg  \n",
      "2               0.993735          0.993493      0.990244  LogReg  \n",
      "3               0.993410          0.993247      0.990036  LogReg  \n",
      "4               0.992870          0.992738      0.984070  LogReg  \n",
      "5               0.986714          0.986020      0.958965     KNN  \n",
      "6               0.985526          0.984921      0.932783     KNN  \n",
      "7               0.987146          0.986146      0.948712     KNN  \n",
      "8               0.985632          0.985061      0.945536     KNN  \n",
      "9               0.987037          0.986416      0.945523     KNN  \n",
      "10              0.986822          0.985486      0.911595     SVM  \n",
      "11              0.987146          0.985843      0.903848     SVM  \n",
      "12              0.987038          0.985737      0.915969     SVM  \n",
      "13              0.987469          0.986635      0.906559     SVM  \n",
      "14              0.988657          0.987692      0.924437     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      1.00      0.92     11163\n",
      "      benign       0.00      0.00      0.00      1965\n",
      "\n",
      "    accuracy                           0.85     13128\n",
      "   macro avg       0.43      0.50      0.46     13128\n",
      "weighted avg       0.72      0.85      0.78     13128\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.725244    0.013000       0.992871                 0.992652   \n",
      "1   0.754731    0.015001       0.991791                 0.991581   \n",
      "2   0.693568    0.011997       0.993735                 0.993570   \n",
      "3   0.717081    0.012996       0.993410                 0.993215   \n",
      "4   0.708147    0.011003       0.992870                 0.992675   \n",
      "5   0.051004    3.418969       0.986714                 0.985859   \n",
      "6   0.055000    1.441328       0.985526                 0.984614   \n",
      "7   0.053998    1.373265       0.987146                 0.986242   \n",
      "8   0.049005    1.411993       0.985632                 0.984768   \n",
      "9   0.047046    1.391654       0.987037                 0.986186   \n",
      "10  7.706005    4.359030       0.986822                 0.986149   \n",
      "11  7.529908    4.257102       0.987146                 0.986347   \n",
      "12  7.834819    4.351607       0.987038                 0.986252   \n",
      "13  7.962861    4.299286       0.987469                 0.986612   \n",
      "14  7.649261    4.323349       0.988657                 0.988005   \n",
      "15  0.128990    0.069997       0.999568                 0.999568   \n",
      "16  0.124934    0.071994       0.999352                 0.999352   \n",
      "17  0.126007    0.069993       0.999352                 0.999352   \n",
      "18  0.150001    0.072999       0.999352                 0.999352   \n",
      "19  0.126115    0.070000       0.999676                 0.999676   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.992871          0.992684      0.991673  LogReg  \n",
      "1               0.991791          0.991661      0.981386  LogReg  \n",
      "2               0.993735          0.993493      0.990244  LogReg  \n",
      "3               0.993410          0.993247      0.990036  LogReg  \n",
      "4               0.992870          0.992738      0.984070  LogReg  \n",
      "5               0.986714          0.986020      0.958965     KNN  \n",
      "6               0.985526          0.984921      0.932783     KNN  \n",
      "7               0.987146          0.986146      0.948712     KNN  \n",
      "8               0.985632          0.985061      0.945536     KNN  \n",
      "9               0.987037          0.986416      0.945523     KNN  \n",
      "10              0.986822          0.985486      0.911595     SVM  \n",
      "11              0.987146          0.985843      0.903848     SVM  \n",
      "12              0.987038          0.985737      0.915969     SVM  \n",
      "13              0.987469          0.986635      0.906559     SVM  \n",
      "14              0.988657          0.987692      0.924437     SVM  \n",
      "15              0.999568          0.999566      1.000000     GNB  \n",
      "16              0.999352          0.999348      0.996047     GNB  \n",
      "17              0.999352          0.999348      1.000000     GNB  \n",
      "18              0.999352          0.999348      1.000000     GNB  \n",
      "19              0.999676          0.999675      0.997967     GNB  \n",
      "544.7639932000311\n"
     ]
    }
   ],
   "source": [
    "## Train: Webmine, Test: WebminePool\n",
    " \n",
    "df_malicious_Train = pd.concat([df5])\n",
    "df_malicious_Test = pd.concat([df6])\n",
    "\n",
    "\n",
    "df_benign_Train = pd.concat([df13,df14,df15,df16,df17])[:450000]\n",
    "df_benign_Test = pd.concat([df13,df14,df15,df16,df17])[450000:]\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    " \n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 19643\n",
      "malicious_test: 12871\n",
      "benign_train: 450000\n",
      "benign_test: 111625\n",
      "After droppping NAN rows: \n",
      "malicious_train: 19643\n",
      "malicious_test: 12871\n",
      "benign_train: 450000\n",
      "benign_test: 111625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:13<00:00,  2.98it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:09<00:00,  4.25it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [05:57<00:00,  8.95s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [01:28<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.98      0.98     11163\n",
      "      benign       0.81      0.84      0.82      1288\n",
      "\n",
      "    accuracy                           0.96     12451\n",
      "   macro avg       0.90      0.91      0.90     12451\n",
      "weighted avg       0.96      0.96      0.96     12451\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.777625    0.014003       0.992122                 0.991955   \n",
      "1  0.797417    0.012997       0.991589                 0.991378   \n",
      "2  0.792386    0.015007       0.990951                 0.990754   \n",
      "3  0.786557    0.013003       0.992228                 0.992075   \n",
      "4  0.765009    0.013998       0.992654                 0.992511   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.992122          0.991986      0.992900  LogReg  \n",
      "1              0.991589          0.991386      0.993919  LogReg  \n",
      "2              0.990951          0.990811      0.990048  LogReg  \n",
      "3              0.992228          0.992115      0.993829  LogReg  \n",
      "4              0.992654          0.992546      0.993647  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      0.93      0.95     11163\n",
      "      benign       0.55      0.71      0.62      1288\n",
      "\n",
      "    accuracy                           0.91     12451\n",
      "   macro avg       0.76      0.82      0.78     12451\n",
      "weighted avg       0.92      0.91      0.91     12451\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.777625    0.014003       0.992122                 0.991955   \n",
      "1  0.797417    0.012997       0.991589                 0.991378   \n",
      "2  0.792386    0.015007       0.990951                 0.990754   \n",
      "3  0.786557    0.013003       0.992228                 0.992075   \n",
      "4  0.765009    0.013998       0.992654                 0.992511   \n",
      "5  0.063089    1.844577       0.981795                 0.980813   \n",
      "6  0.072001    1.871435       0.981050                 0.980220   \n",
      "7  0.071554    1.815698       0.979240                 0.977949   \n",
      "8  0.071071    1.865594       0.981156                 0.980218   \n",
      "9  0.073993    1.850474       0.981263                 0.980832   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.992122          0.991986      0.992900  LogReg  \n",
      "1              0.991589          0.991386      0.993919  LogReg  \n",
      "2              0.990951          0.990811      0.990048  LogReg  \n",
      "3              0.992228          0.992115      0.993829  LogReg  \n",
      "4              0.992654          0.992546      0.993647  LogReg  \n",
      "5              0.981795          0.981053      0.960895     KNN  \n",
      "6              0.981050          0.980527      0.961054     KNN  \n",
      "7              0.979240          0.978300      0.936164     KNN  \n",
      "8              0.981156          0.980525      0.951135     KNN  \n",
      "9              0.981263          0.981024      0.962520     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      0.64      0.78     11163\n",
      "      benign       0.24      0.98      0.38      1288\n",
      "\n",
      "    accuracy                           0.67     12451\n",
      "   macro avg       0.62      0.81      0.58     12451\n",
      "weighted avg       0.92      0.67      0.74     12451\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    0.777625    0.014003       0.992122                 0.991955   \n",
      "1    0.797417    0.012997       0.991589                 0.991378   \n",
      "2    0.792386    0.015007       0.990951                 0.990754   \n",
      "3    0.786557    0.013003       0.992228                 0.992075   \n",
      "4    0.765009    0.013998       0.992654                 0.992511   \n",
      "5    0.063089    1.844577       0.981795                 0.980813   \n",
      "6    0.072001    1.871435       0.981050                 0.980220   \n",
      "7    0.071554    1.815698       0.979240                 0.977949   \n",
      "8    0.071071    1.865594       0.981156                 0.980218   \n",
      "9    0.073993    1.850474       0.981263                 0.980832   \n",
      "10  15.632290    9.327137       0.986905                 0.986387   \n",
      "11  15.743464    8.845908       0.985202                 0.984501   \n",
      "12  15.873356    8.760106       0.984244                 0.983521   \n",
      "13  15.186202    9.105534       0.983818                 0.983000   \n",
      "14  15.029200    8.807798       0.983605                 0.982694   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.992122          0.991986      0.992900  LogReg  \n",
      "1               0.991589          0.991386      0.993919  LogReg  \n",
      "2               0.990951          0.990811      0.990048  LogReg  \n",
      "3               0.992228          0.992115      0.993829  LogReg  \n",
      "4               0.992654          0.992546      0.993647  LogReg  \n",
      "5               0.981795          0.981053      0.960895     KNN  \n",
      "6               0.981050          0.980527      0.961054     KNN  \n",
      "7               0.979240          0.978300      0.936164     KNN  \n",
      "8               0.981156          0.980525      0.951135     KNN  \n",
      "9               0.981263          0.981024      0.962520     KNN  \n",
      "10              0.986905          0.986316      0.965314     SVM  \n",
      "11              0.985202          0.984321      0.956772     SVM  \n",
      "12              0.984244          0.983186      0.963410     SVM  \n",
      "13              0.983818          0.982702      0.947110     SVM  \n",
      "14              0.983605          0.982769      0.971963     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.94      1.00      0.97     11163\n",
      "      benign       0.95      0.43      0.59      1288\n",
      "\n",
      "    accuracy                           0.94     12451\n",
      "   macro avg       0.94      0.71      0.78     12451\n",
      "weighted avg       0.94      0.94      0.93     12451\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    0.777625    0.014003       0.992122                 0.991955   \n",
      "1    0.797417    0.012997       0.991589                 0.991378   \n",
      "2    0.792386    0.015007       0.990951                 0.990754   \n",
      "3    0.786557    0.013003       0.992228                 0.992075   \n",
      "4    0.765009    0.013998       0.992654                 0.992511   \n",
      "5    0.063089    1.844577       0.981795                 0.980813   \n",
      "6    0.072001    1.871435       0.981050                 0.980220   \n",
      "7    0.071554    1.815698       0.979240                 0.977949   \n",
      "8    0.071071    1.865594       0.981156                 0.980218   \n",
      "9    0.073993    1.850474       0.981263                 0.980832   \n",
      "10  15.632290    9.327137       0.986905                 0.986387   \n",
      "11  15.743464    8.845908       0.985202                 0.984501   \n",
      "12  15.873356    8.760106       0.984244                 0.983521   \n",
      "13  15.186202    9.105534       0.983818                 0.983000   \n",
      "14  15.029200    8.807798       0.983605                 0.982694   \n",
      "15   0.190962    0.107980       0.998722                 0.998736   \n",
      "16   0.182886    0.109998       0.999681                 0.999681   \n",
      "17   0.198332    0.118181       0.999042                 0.999046   \n",
      "18   0.178017    0.099209       0.998935                 0.998954   \n",
      "19   0.172288    0.095632       0.998935                 0.998943   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.992122          0.991986      0.992900  LogReg  \n",
      "1               0.991589          0.991386      0.993919  LogReg  \n",
      "2               0.990951          0.990811      0.990048  LogReg  \n",
      "3               0.992228          0.992115      0.993829  LogReg  \n",
      "4               0.992654          0.992546      0.993647  LogReg  \n",
      "5               0.981795          0.981053      0.960895     KNN  \n",
      "6               0.981050          0.980527      0.961054     KNN  \n",
      "7               0.979240          0.978300      0.936164     KNN  \n",
      "8               0.981156          0.980525      0.951135     KNN  \n",
      "9               0.981263          0.981024      0.962520     KNN  \n",
      "10              0.986905          0.986316      0.965314     SVM  \n",
      "11              0.985202          0.984321      0.956772     SVM  \n",
      "12              0.984244          0.983186      0.963410     SVM  \n",
      "13              0.983818          0.982702      0.947110     SVM  \n",
      "14              0.983605          0.982769      0.971963     SVM  \n",
      "15              0.998722          0.998727      0.999496     GNB  \n",
      "16              0.999681          0.999681      0.998593     GNB  \n",
      "17              0.999042          0.999044      0.998414     GNB  \n",
      "18              0.998935          0.998941      0.999499     GNB  \n",
      "19              0.998935          0.998938      0.999608     GNB  \n",
      "722.4304271999863\n"
     ]
    }
   ],
   "source": [
    "## Train: WebminePool, Test: Webmine\n",
    " \n",
    "df_malicious_Train = pd.concat([df6])\n",
    "df_malicious_Test = pd.concat([df5])\n",
    "\n",
    "\n",
    "df_benign_Train = pd.concat([df13,df14,df15,df16,df17])[:450000]\n",
    "df_benign_Test = pd.concat([df13,df14,df15,df16,df17])[450000:]\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    " \n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 11745\n",
      "malicious_test: 41572\n",
      "benign_train: 284817\n",
      "benign_test: 284817\n",
      "After droppping NAN rows: \n",
      "malicious_train: 11745\n",
      "malicious_test: 41572\n",
      "benign_train: 284817\n",
      "benign_test: 284817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:10<00:00,  3.64it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:33<00:00,  1.19it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [03:47<00:00,  5.68s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [03:47<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.87      1.00      0.93     28482\n",
      "      benign       0.54      0.02      0.04      4158\n",
      "\n",
      "    accuracy                           0.87     32640\n",
      "   macro avg       0.71      0.51      0.49     32640\n",
      "weighted avg       0.83      0.87      0.82     32640\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.639015    0.017003       0.995448                 0.995535   \n",
      "1  0.585791    0.013031       0.995617                 0.995577   \n",
      "2  0.578747    0.015935       0.994942                 0.994961   \n",
      "3  0.590958    0.012990       0.995616                 0.995659   \n",
      "4  0.556219    0.014987       0.995448                 0.995505   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.995448          0.995483      0.999132  LogReg  \n",
      "1              0.995617          0.995591      0.998903  LogReg  \n",
      "2              0.994942          0.994951      0.999011  LogReg  \n",
      "3              0.995616          0.995635      0.999229  LogReg  \n",
      "4              0.995448          0.995472      0.999502  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.88      1.00      0.93     28482\n",
      "      benign       0.74      0.03      0.05      4158\n",
      "\n",
      "    accuracy                           0.87     32640\n",
      "   macro avg       0.81      0.51      0.49     32640\n",
      "weighted avg       0.86      0.87      0.82     32640\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.639015    0.017003       0.995448                 0.995535   \n",
      "1  0.585791    0.013031       0.995617                 0.995577   \n",
      "2  0.578747    0.015935       0.994942                 0.994961   \n",
      "3  0.590958    0.012990       0.995616                 0.995659   \n",
      "4  0.556219    0.014987       0.995448                 0.995505   \n",
      "5  0.059981    0.833547       0.992414                 0.992782   \n",
      "6  0.050908    0.838054       0.991571                 0.991812   \n",
      "7  0.046000    0.837096       0.987523                 0.987772   \n",
      "8  0.050001    0.836622       0.991570                 0.991730   \n",
      "9  0.050008    0.843719       0.992244                 0.992442   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.995448          0.995483      0.999132  LogReg  \n",
      "1              0.995617          0.995591      0.998903  LogReg  \n",
      "2              0.994942          0.994951      0.999011  LogReg  \n",
      "3              0.995616          0.995635      0.999229  LogReg  \n",
      "4              0.995448          0.995472      0.999502  LogReg  \n",
      "5              0.992414          0.992549      0.982715     KNN  \n",
      "6              0.991571          0.991669      0.983976     KNN  \n",
      "7              0.987523          0.987634      0.978644     KNN  \n",
      "8              0.991570          0.991639      0.980834     KNN  \n",
      "9              0.992244          0.992326      0.991415     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.87      1.00      0.93     28482\n",
      "      benign       0.56      0.01      0.01      4158\n",
      "\n",
      "    accuracy                           0.87     32640\n",
      "   macro avg       0.72      0.50      0.47     32640\n",
      "weighted avg       0.83      0.87      0.81     32640\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.639015    0.017003       0.995448                 0.995535   \n",
      "1   0.585791    0.013031       0.995617                 0.995577   \n",
      "2   0.578747    0.015935       0.994942                 0.994961   \n",
      "3   0.590958    0.012990       0.995616                 0.995659   \n",
      "4   0.556219    0.014987       0.995448                 0.995505   \n",
      "5   0.059981    0.833547       0.992414                 0.992782   \n",
      "6   0.050908    0.838054       0.991571                 0.991812   \n",
      "7   0.046000    0.837096       0.987523                 0.987772   \n",
      "8   0.050001    0.836622       0.991570                 0.991730   \n",
      "9   0.050008    0.843719       0.992244                 0.992442   \n",
      "10  6.794098    4.363452       0.985502                 0.984720   \n",
      "11  6.682529    4.411610       0.984659                 0.983861   \n",
      "12  6.679982    4.286742       0.983139                 0.982263   \n",
      "13  6.900084    4.413275       0.988198                 0.987716   \n",
      "14  6.646184    4.374586       0.988872                 0.988661   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.995448          0.995483      0.999132  LogReg  \n",
      "1               0.995617          0.995591      0.998903  LogReg  \n",
      "2               0.994942          0.994951      0.999011  LogReg  \n",
      "3               0.995616          0.995635      0.999229  LogReg  \n",
      "4               0.995448          0.995472      0.999502  LogReg  \n",
      "5               0.992414          0.992549      0.982715     KNN  \n",
      "6               0.991571          0.991669      0.983976     KNN  \n",
      "7               0.987523          0.987634      0.978644     KNN  \n",
      "8               0.991570          0.991639      0.980834     KNN  \n",
      "9               0.992244          0.992326      0.991415     KNN  \n",
      "10              0.985502          0.984564      0.996404     SVM  \n",
      "11              0.984659          0.983786      0.996184     SVM  \n",
      "12              0.983139          0.982257      0.995729     SVM  \n",
      "13              0.988198          0.987710      0.996397     SVM  \n",
      "14              0.988872          0.988749      0.996776     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.87      1.00      0.93     28482\n",
      "      benign       0.00      0.00      0.00      4158\n",
      "\n",
      "    accuracy                           0.87     32640\n",
      "   macro avg       0.44      0.50      0.47     32640\n",
      "weighted avg       0.76      0.87      0.81     32640\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.639015    0.017003       0.995448                 0.995535   \n",
      "1   0.585791    0.013031       0.995617                 0.995577   \n",
      "2   0.578747    0.015935       0.994942                 0.994961   \n",
      "3   0.590958    0.012990       0.995616                 0.995659   \n",
      "4   0.556219    0.014987       0.995448                 0.995505   \n",
      "5   0.059981    0.833547       0.992414                 0.992782   \n",
      "6   0.050908    0.838054       0.991571                 0.991812   \n",
      "7   0.046000    0.837096       0.987523                 0.987772   \n",
      "8   0.050001    0.836622       0.991570                 0.991730   \n",
      "9   0.050008    0.843719       0.992244                 0.992442   \n",
      "10  6.794098    4.363452       0.985502                 0.984720   \n",
      "11  6.682529    4.411610       0.984659                 0.983861   \n",
      "12  6.679982    4.286742       0.983139                 0.982263   \n",
      "13  6.900084    4.413275       0.988198                 0.987716   \n",
      "14  6.646184    4.374586       0.988872                 0.988661   \n",
      "15  0.132446    0.083920       1.000000                 1.000000   \n",
      "16  0.157614    0.095395       1.000000                 1.000000   \n",
      "17  0.150651    0.064998       1.000000                 1.000000   \n",
      "18  0.105434    0.085104       1.000000                 1.000000   \n",
      "19  0.132002    0.050000       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.995448          0.995483      0.999132  LogReg  \n",
      "1               0.995617          0.995591      0.998903  LogReg  \n",
      "2               0.994942          0.994951      0.999011  LogReg  \n",
      "3               0.995616          0.995635      0.999229  LogReg  \n",
      "4               0.995448          0.995472      0.999502  LogReg  \n",
      "5               0.992414          0.992549      0.982715     KNN  \n",
      "6               0.991571          0.991669      0.983976     KNN  \n",
      "7               0.987523          0.987634      0.978644     KNN  \n",
      "8               0.991570          0.991639      0.980834     KNN  \n",
      "9               0.992244          0.992326      0.991415     KNN  \n",
      "10              0.985502          0.984564      0.996404     SVM  \n",
      "11              0.984659          0.983786      0.996184     SVM  \n",
      "12              0.983139          0.982257      0.995729     SVM  \n",
      "13              0.988198          0.987710      0.996397     SVM  \n",
      "14              0.988872          0.988749      0.996776     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              1.000000          1.000000      1.000000     GNB  \n",
      "17              1.000000          1.000000      1.000000     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "675.7178897999693\n"
     ]
    }
   ],
   "source": [
    "## Train: Raspberry (server), Test: binary (WebOS)\n",
    " \n",
    "df_malicious_Train = pd.concat([df4])\n",
    "df_malicious_Test = pd.concat([df1])\n",
    "\n",
    "\n",
    "df_benign_Train = pd.concat([df14,df15,df16,df17])\n",
    "df_benign_Test = pd.concat([df14,df15,df16,df17])\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    " \n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 11745\n",
      "malicious_test: 19643\n",
      "benign_train: 450000\n",
      "benign_test: 111625\n",
      "After droppping NAN rows: \n",
      "malicious_train: 11745\n",
      "malicious_test: 19643\n",
      "benign_train: 450000\n",
      "benign_test: 111625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:10<00:00,  3.65it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:17<00:00,  2.31it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [06:00<00:00,  9.01s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [01:29<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.86      1.00      0.93     11163\n",
      "      benign       1.00      0.11      0.20      1965\n",
      "\n",
      "    accuracy                           0.87     13128\n",
      "   macro avg       0.93      0.56      0.56     13128\n",
      "weighted avg       0.88      0.87      0.82     13128\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.882171    0.013005       0.997834                 0.997817   \n",
      "1  0.811040    0.013005       0.997185                 0.997308   \n",
      "2  0.834068    0.012995       0.997834                 0.997834   \n",
      "3  0.771219    0.014004       0.997401                 0.997458   \n",
      "4  0.805983    0.012996       0.997834                 0.997869   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997834          0.997822      0.999830  LogReg  \n",
      "1              0.997185          0.997225      0.999401  LogReg  \n",
      "2              0.997834          0.997834      0.999590  LogReg  \n",
      "3              0.997401          0.997423      0.999561  LogReg  \n",
      "4              0.997834          0.997848      0.999840  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.88      0.98      0.93     11163\n",
      "      benign       0.72      0.23      0.35      1965\n",
      "\n",
      "    accuracy                           0.87     13128\n",
      "   macro avg       0.80      0.61      0.64     13128\n",
      "weighted avg       0.86      0.87      0.84     13128\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.882171    0.013005       0.997834                 0.997817   \n",
      "1  0.811040    0.013005       0.997185                 0.997308   \n",
      "2  0.834068    0.012995       0.997834                 0.997834   \n",
      "3  0.771219    0.014004       0.997401                 0.997458   \n",
      "4  0.805983    0.012996       0.997834                 0.997869   \n",
      "5  0.064957    1.971108       0.995127                 0.995227   \n",
      "6  0.073997    1.866834       0.995236                 0.995329   \n",
      "7  0.073993    1.893914       0.994586                 0.994688   \n",
      "8  0.074103    1.915648       0.994153                 0.994429   \n",
      "9  0.074016    1.886320       0.993070                 0.993268   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997834          0.997822      0.999830  LogReg  \n",
      "1              0.997185          0.997225      0.999401  LogReg  \n",
      "2              0.997834          0.997834      0.999590  LogReg  \n",
      "3              0.997401          0.997423      0.999561  LogReg  \n",
      "4              0.997834          0.997848      0.999840  LogReg  \n",
      "5              0.995127          0.995169      0.993183     KNN  \n",
      "6              0.995236          0.995275      0.988083     KNN  \n",
      "7              0.994586          0.994630      0.988337     KNN  \n",
      "8              0.994153          0.994259      0.990292     KNN  \n",
      "9              0.993070          0.993155      0.990039     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.90      0.99      0.94     11163\n",
      "      benign       0.89      0.35      0.50      1965\n",
      "\n",
      "    accuracy                           0.90     13128\n",
      "   macro avg       0.89      0.67      0.72     13128\n",
      "weighted avg       0.90      0.90      0.88     13128\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.882171    0.013005       0.997834                 0.997817   \n",
      "1   0.811040    0.013005       0.997185                 0.997308   \n",
      "2   0.834068    0.012995       0.997834                 0.997834   \n",
      "3   0.771219    0.014004       0.997401                 0.997458   \n",
      "4   0.805983    0.012996       0.997834                 0.997869   \n",
      "5   0.064957    1.971108       0.995127                 0.995227   \n",
      "6   0.073997    1.866834       0.995236                 0.995329   \n",
      "7   0.073993    1.893914       0.994586                 0.994688   \n",
      "8   0.074103    1.915648       0.994153                 0.994429   \n",
      "9   0.074016    1.886320       0.993070                 0.993268   \n",
      "10  8.851659    5.519401       0.992745                 0.992885   \n",
      "11  9.592621    5.488016       0.993503                 0.994108   \n",
      "12  8.997516    5.795268       0.995885                 0.995967   \n",
      "13  8.900702    5.693743       0.991446                 0.992087   \n",
      "14  9.013410    5.332126       0.993828                 0.994097   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997834          0.997822      0.999830  LogReg  \n",
      "1               0.997185          0.997225      0.999401  LogReg  \n",
      "2               0.997834          0.997834      0.999590  LogReg  \n",
      "3               0.997401          0.997423      0.999561  LogReg  \n",
      "4               0.997834          0.997848      0.999840  LogReg  \n",
      "5               0.995127          0.995169      0.993183     KNN  \n",
      "6               0.995236          0.995275      0.988083     KNN  \n",
      "7               0.994586          0.994630      0.988337     KNN  \n",
      "8               0.994153          0.994259      0.990292     KNN  \n",
      "9               0.993070          0.993155      0.990039     KNN  \n",
      "10              0.992745          0.992807      0.998398     SVM  \n",
      "11              0.993503          0.993709      0.998186     SVM  \n",
      "12              0.995885          0.995919      0.998794     SVM  \n",
      "13              0.991446          0.991690      0.997715     SVM  \n",
      "14              0.993828          0.993934      0.998741     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.85      1.00      0.92     11163\n",
      "      benign       0.00      0.00      0.00      1965\n",
      "\n",
      "    accuracy                           0.85     13128\n",
      "   macro avg       0.43      0.50      0.46     13128\n",
      "weighted avg       0.72      0.85      0.78     13128\n",
      "\n",
      "    fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0   0.882171    0.013005       0.997834                 0.997817   \n",
      "1   0.811040    0.013005       0.997185                 0.997308   \n",
      "2   0.834068    0.012995       0.997834                 0.997834   \n",
      "3   0.771219    0.014004       0.997401                 0.997458   \n",
      "4   0.805983    0.012996       0.997834                 0.997869   \n",
      "5   0.064957    1.971108       0.995127                 0.995227   \n",
      "6   0.073997    1.866834       0.995236                 0.995329   \n",
      "7   0.073993    1.893914       0.994586                 0.994688   \n",
      "8   0.074103    1.915648       0.994153                 0.994429   \n",
      "9   0.074016    1.886320       0.993070                 0.993268   \n",
      "10  8.851659    5.519401       0.992745                 0.992885   \n",
      "11  9.592621    5.488016       0.993503                 0.994108   \n",
      "12  8.997516    5.795268       0.995885                 0.995967   \n",
      "13  8.900702    5.693743       0.991446                 0.992087   \n",
      "14  9.013410    5.332126       0.993828                 0.994097   \n",
      "15  0.156660    0.113253       1.000000                 1.000000   \n",
      "16  0.212743    0.123004       1.000000                 1.000000   \n",
      "17  0.202204    0.086047       1.000000                 1.000000   \n",
      "18  0.215043    0.133611       1.000000                 1.000000   \n",
      "19  0.212934    0.112603       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997834          0.997822      0.999830  LogReg  \n",
      "1               0.997185          0.997225      0.999401  LogReg  \n",
      "2               0.997834          0.997834      0.999590  LogReg  \n",
      "3               0.997401          0.997423      0.999561  LogReg  \n",
      "4               0.997834          0.997848      0.999840  LogReg  \n",
      "5               0.995127          0.995169      0.993183     KNN  \n",
      "6               0.995236          0.995275      0.988083     KNN  \n",
      "7               0.994586          0.994630      0.988337     KNN  \n",
      "8               0.994153          0.994259      0.990292     KNN  \n",
      "9               0.993070          0.993155      0.990039     KNN  \n",
      "10              0.992745          0.992807      0.998398     SVM  \n",
      "11              0.993503          0.993709      0.998186     SVM  \n",
      "12              0.995885          0.995919      0.998794     SVM  \n",
      "13              0.991446          0.991690      0.997715     SVM  \n",
      "14              0.993828          0.993934      0.998741     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              1.000000          1.000000      1.000000     GNB  \n",
      "17              1.000000          1.000000      1.000000     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "673.7715173999895\n"
     ]
    }
   ],
   "source": [
    "## Train: Binary (raspberry), Test: in-browser (aggressive) (raspberry)\n",
    " \n",
    "df_malicious_Train = pd.concat([df4])\n",
    "df_malicious_Test = pd.concat([df6])\n",
    "\n",
    "df_benign_Train = pd.concat([df13,df14,df15,df16,df17])[:450000]\n",
    "df_benign_Test = pd.concat([df13,df14,df15,df16,df17])[450000:]\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    " \n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 11745\n",
      "malicious_test: 3519\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n",
      "After droppping NAN rows: \n",
      "malicious_train: 11745\n",
      "malicious_test: 3519\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:10<00:00,  3.67it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:04<00:00,  8.59it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [07:32<00:00, 11.30s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [07:29<00:00, 11.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     56163\n",
      "      benign       0.25      0.16      0.20       352\n",
      "\n",
      "    accuracy                           0.99     56515\n",
      "   macro avg       0.62      0.58      0.60     56515\n",
      "weighted avg       0.99      0.99      0.99     56515\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.034597    0.017001       0.997820                 0.997846   \n",
      "1  1.010359    0.015003       0.997733                 0.997704   \n",
      "2  1.052906    0.015987       0.998343                 0.998365   \n",
      "3  0.981652    0.015001       0.996773                 0.996867   \n",
      "4  0.965628    0.015007       0.998256                 0.998249   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997820          0.997831      0.999633  LogReg  \n",
      "1              0.997733          0.997709      0.999634  LogReg  \n",
      "2              0.998343          0.998352      0.999773  LogReg  \n",
      "3              0.996773          0.996810      0.999061  LogReg  \n",
      "4              0.998256          0.998252      0.999784  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     56163\n",
      "      benign       0.12      0.05      0.07       352\n",
      "\n",
      "    accuracy                           0.99     56515\n",
      "   macro avg       0.56      0.52      0.53     56515\n",
      "weighted avg       0.99      0.99      0.99     56515\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.034597    0.017001       0.997820                 0.997846   \n",
      "1  1.010359    0.015003       0.997733                 0.997704   \n",
      "2  1.052906    0.015987       0.998343                 0.998365   \n",
      "3  0.981652    0.015001       0.996773                 0.996867   \n",
      "4  0.965628    0.015007       0.998256                 0.998249   \n",
      "5  0.072646    2.704717       0.995378                 0.995497   \n",
      "6  0.085000    2.766476       0.995291                 0.995354   \n",
      "7  0.084707    2.798704       0.995553                 0.995676   \n",
      "8  0.083318    2.818565       0.994070                 0.994208   \n",
      "9  0.092931    2.761036       0.994244                 0.994295   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997820          0.997831      0.999633  LogReg  \n",
      "1              0.997733          0.997709      0.999634  LogReg  \n",
      "2              0.998343          0.998352      0.999773  LogReg  \n",
      "3              0.996773          0.996810      0.999061  LogReg  \n",
      "4              0.998256          0.998252      0.999784  LogReg  \n",
      "5              0.995378          0.995428      0.990778     KNN  \n",
      "6              0.995291          0.995320      0.986696     KNN  \n",
      "7              0.995553          0.995604      0.983624     KNN  \n",
      "8              0.994070          0.994131      0.983761     KNN  \n",
      "9              0.994244          0.994268      0.979468     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     56163\n",
      "      benign       0.18      0.15      0.17       352\n",
      "\n",
      "    accuracy                           0.99     56515\n",
      "   macro avg       0.59      0.57      0.58     56515\n",
      "weighted avg       0.99      0.99      0.99     56515\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.034597    0.017001       0.997820                 0.997846   \n",
      "1    1.010359    0.015003       0.997733                 0.997704   \n",
      "2    1.052906    0.015987       0.998343                 0.998365   \n",
      "3    0.981652    0.015001       0.996773                 0.996867   \n",
      "4    0.965628    0.015007       0.998256                 0.998249   \n",
      "5    0.072646    2.704717       0.995378                 0.995497   \n",
      "6    0.085000    2.766476       0.995291                 0.995354   \n",
      "7    0.084707    2.798704       0.995553                 0.995676   \n",
      "8    0.083318    2.818565       0.994070                 0.994208   \n",
      "9    0.092931    2.761036       0.994244                 0.994295   \n",
      "10  14.810010    9.045150       0.991280                 0.990741   \n",
      "11  14.503066    9.341008       0.992326                 0.991924   \n",
      "12  15.184426    9.361575       0.992850                 0.992496   \n",
      "13  14.594189    9.377263       0.993372                 0.993224   \n",
      "14  14.573317    9.300648       0.993459                 0.993170   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997820          0.997831      0.999633  LogReg  \n",
      "1               0.997733          0.997709      0.999634  LogReg  \n",
      "2               0.998343          0.998352      0.999773  LogReg  \n",
      "3               0.996773          0.996810      0.999061  LogReg  \n",
      "4               0.998256          0.998252      0.999784  LogReg  \n",
      "5               0.995378          0.995428      0.990778     KNN  \n",
      "6               0.995291          0.995320      0.986696     KNN  \n",
      "7               0.995553          0.995604      0.983624     KNN  \n",
      "8               0.994070          0.994131      0.983761     KNN  \n",
      "9               0.994244          0.994268      0.979468     KNN  \n",
      "10              0.991280          0.990700      0.997734     SVM  \n",
      "11              0.992326          0.991967      0.997981     SVM  \n",
      "12              0.992850          0.992566      0.997851     SVM  \n",
      "13              0.993372          0.993286      0.997254     SVM  \n",
      "14              0.993459          0.993214      0.998058     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     56163\n",
      "      benign       1.00      0.41      0.59       352\n",
      "\n",
      "    accuracy                           1.00     56515\n",
      "   macro avg       1.00      0.71      0.79     56515\n",
      "weighted avg       1.00      1.00      1.00     56515\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.034597    0.017001       0.997820                 0.997846   \n",
      "1    1.010359    0.015003       0.997733                 0.997704   \n",
      "2    1.052906    0.015987       0.998343                 0.998365   \n",
      "3    0.981652    0.015001       0.996773                 0.996867   \n",
      "4    0.965628    0.015007       0.998256                 0.998249   \n",
      "5    0.072646    2.704717       0.995378                 0.995497   \n",
      "6    0.085000    2.766476       0.995291                 0.995354   \n",
      "7    0.084707    2.798704       0.995553                 0.995676   \n",
      "8    0.083318    2.818565       0.994070                 0.994208   \n",
      "9    0.092931    2.761036       0.994244                 0.994295   \n",
      "10  14.810010    9.045150       0.991280                 0.990741   \n",
      "11  14.503066    9.341008       0.992326                 0.991924   \n",
      "12  15.184426    9.361575       0.992850                 0.992496   \n",
      "13  14.594189    9.377263       0.993372                 0.993224   \n",
      "14  14.573317    9.300648       0.993459                 0.993170   \n",
      "15   0.215969    0.124714       1.000000                 1.000000   \n",
      "16   0.213958    0.103690       1.000000                 1.000000   \n",
      "17   0.210155    0.156590       1.000000                 1.000000   \n",
      "18   0.275016    0.143054       1.000000                 1.000000   \n",
      "19   0.248664    0.102970       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997820          0.997831      0.999633  LogReg  \n",
      "1               0.997733          0.997709      0.999634  LogReg  \n",
      "2               0.998343          0.998352      0.999773  LogReg  \n",
      "3               0.996773          0.996810      0.999061  LogReg  \n",
      "4               0.998256          0.998252      0.999784  LogReg  \n",
      "5               0.995378          0.995428      0.990778     KNN  \n",
      "6               0.995291          0.995320      0.986696     KNN  \n",
      "7               0.995553          0.995604      0.983624     KNN  \n",
      "8               0.994070          0.994131      0.983761     KNN  \n",
      "9               0.994244          0.994268      0.979468     KNN  \n",
      "10              0.991280          0.990700      0.997734     SVM  \n",
      "11              0.992326          0.991967      0.997981     SVM  \n",
      "12              0.992850          0.992566      0.997851     SVM  \n",
      "13              0.993372          0.993286      0.997254     SVM  \n",
      "14              0.993459          0.993214      0.998058     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              1.000000          1.000000      1.000000     GNB  \n",
      "17              1.000000          1.000000      1.000000     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "1298.099140300008\n"
     ]
    }
   ],
   "source": [
    "## Train: Binary  (raspberry), Test: in-browser (robust)  (raspberry)\n",
    "  \n",
    "df_malicious_Train = pd.concat([df4])\n",
    "df_malicious_Test = pd.concat([df3])\n",
    "\n",
    "df_benign_Train = pd.concat([df13,df14,df15,df16,df17])\n",
    "df_benign_Test = pd.concat([df13,df14,df15,df16,df17])\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    "\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 11745\n",
      "malicious_test: 9880\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n",
      "After droppping NAN rows: \n",
      "malicious_train: 11745\n",
      "malicious_test: 9880\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:10<00:00,  3.65it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:09<00:00,  4.23it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [07:30<00:00, 11.25s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [06:48<00:00, 10.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     56163\n",
      "      benign       0.90      0.45      0.60       988\n",
      "\n",
      "    accuracy                           0.99     57151\n",
      "   macro avg       0.95      0.72      0.80     57151\n",
      "weighted avg       0.99      0.99      0.99     57151\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.992635    0.016002       0.997820                 0.997846   \n",
      "1  0.996677    0.015992       0.997733                 0.997704   \n",
      "2  1.036706    0.015991       0.998343                 0.998365   \n",
      "3  0.976337    0.015002       0.996773                 0.996867   \n",
      "4  0.981000    0.017001       0.998256                 0.998249   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997820          0.997831      0.999633  LogReg  \n",
      "1              0.997733          0.997709      0.999634  LogReg  \n",
      "2              0.998343          0.998352      0.999773  LogReg  \n",
      "3              0.996773          0.996810      0.999061  LogReg  \n",
      "4              0.998256          0.998252      0.999784  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      1.00      0.99     56163\n",
      "      benign       0.58      0.12      0.20       988\n",
      "\n",
      "    accuracy                           0.98     57151\n",
      "   macro avg       0.78      0.56      0.60     57151\n",
      "weighted avg       0.98      0.98      0.98     57151\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.992635    0.016002       0.997820                 0.997846   \n",
      "1  0.996677    0.015992       0.997733                 0.997704   \n",
      "2  1.036706    0.015991       0.998343                 0.998365   \n",
      "3  0.976337    0.015002       0.996773                 0.996867   \n",
      "4  0.981000    0.017001       0.998256                 0.998249   \n",
      "5  0.078989    2.759618       0.995378                 0.995497   \n",
      "6  0.080000    2.754717       0.995291                 0.995354   \n",
      "7  0.072001    2.812221       0.995553                 0.995676   \n",
      "8  0.083057    2.799449       0.994070                 0.994208   \n",
      "9  0.079315    2.730548       0.994244                 0.994295   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997820          0.997831      0.999633  LogReg  \n",
      "1              0.997733          0.997709      0.999634  LogReg  \n",
      "2              0.998343          0.998352      0.999773  LogReg  \n",
      "3              0.996773          0.996810      0.999061  LogReg  \n",
      "4              0.998256          0.998252      0.999784  LogReg  \n",
      "5              0.995378          0.995428      0.990778     KNN  \n",
      "6              0.995291          0.995320      0.986696     KNN  \n",
      "7              0.995553          0.995604      0.983624     KNN  \n",
      "8              0.994070          0.994131      0.983761     KNN  \n",
      "9              0.994244          0.994268      0.979468     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     56163\n",
      "      benign       0.79      0.39      0.52       988\n",
      "\n",
      "    accuracy                           0.99     57151\n",
      "   macro avg       0.89      0.69      0.76     57151\n",
      "weighted avg       0.99      0.99      0.99     57151\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    0.992635    0.016002       0.997820                 0.997846   \n",
      "1    0.996677    0.015992       0.997733                 0.997704   \n",
      "2    1.036706    0.015991       0.998343                 0.998365   \n",
      "3    0.976337    0.015002       0.996773                 0.996867   \n",
      "4    0.981000    0.017001       0.998256                 0.998249   \n",
      "5    0.078989    2.759618       0.995378                 0.995497   \n",
      "6    0.080000    2.754717       0.995291                 0.995354   \n",
      "7    0.072001    2.812221       0.995553                 0.995676   \n",
      "8    0.083057    2.799449       0.994070                 0.994208   \n",
      "9    0.079315    2.730548       0.994244                 0.994295   \n",
      "10  14.445394    8.647218       0.991280                 0.990741   \n",
      "11  14.767838    9.362915       0.992326                 0.991924   \n",
      "12  14.913655    9.288333       0.992850                 0.992496   \n",
      "13  14.645828    9.452429       0.993372                 0.993224   \n",
      "14  14.210512    9.113131       0.993459                 0.993170   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997820          0.997831      0.999633  LogReg  \n",
      "1               0.997733          0.997709      0.999634  LogReg  \n",
      "2               0.998343          0.998352      0.999773  LogReg  \n",
      "3               0.996773          0.996810      0.999061  LogReg  \n",
      "4               0.998256          0.998252      0.999784  LogReg  \n",
      "5               0.995378          0.995428      0.990778     KNN  \n",
      "6               0.995291          0.995320      0.986696     KNN  \n",
      "7               0.995553          0.995604      0.983624     KNN  \n",
      "8               0.994070          0.994131      0.983761     KNN  \n",
      "9               0.994244          0.994268      0.979468     KNN  \n",
      "10              0.991280          0.990700      0.997734     SVM  \n",
      "11              0.992326          0.991967      0.997981     SVM  \n",
      "12              0.992850          0.992566      0.997851     SVM  \n",
      "13              0.993372          0.993286      0.997254     SVM  \n",
      "14              0.993459          0.993214      0.998058     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     56163\n",
      "      benign       1.00      0.85      0.92       988\n",
      "\n",
      "    accuracy                           1.00     57151\n",
      "   macro avg       1.00      0.92      0.96     57151\n",
      "weighted avg       1.00      1.00      1.00     57151\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    0.992635    0.016002       0.997820                 0.997846   \n",
      "1    0.996677    0.015992       0.997733                 0.997704   \n",
      "2    1.036706    0.015991       0.998343                 0.998365   \n",
      "3    0.976337    0.015002       0.996773                 0.996867   \n",
      "4    0.981000    0.017001       0.998256                 0.998249   \n",
      "5    0.078989    2.759618       0.995378                 0.995497   \n",
      "6    0.080000    2.754717       0.995291                 0.995354   \n",
      "7    0.072001    2.812221       0.995553                 0.995676   \n",
      "8    0.083057    2.799449       0.994070                 0.994208   \n",
      "9    0.079315    2.730548       0.994244                 0.994295   \n",
      "10  14.445394    8.647218       0.991280                 0.990741   \n",
      "11  14.767838    9.362915       0.992326                 0.991924   \n",
      "12  14.913655    9.288333       0.992850                 0.992496   \n",
      "13  14.645828    9.452429       0.993372                 0.993224   \n",
      "14  14.210512    9.113131       0.993459                 0.993170   \n",
      "15   0.233016    0.103948       1.000000                 1.000000   \n",
      "16   0.286213    0.134921       1.000000                 1.000000   \n",
      "17   0.254243    0.117079       1.000000                 1.000000   \n",
      "18   0.267510    0.126410       1.000000                 1.000000   \n",
      "19   0.244273    0.107721       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997820          0.997831      0.999633  LogReg  \n",
      "1               0.997733          0.997709      0.999634  LogReg  \n",
      "2               0.998343          0.998352      0.999773  LogReg  \n",
      "3               0.996773          0.996810      0.999061  LogReg  \n",
      "4               0.998256          0.998252      0.999784  LogReg  \n",
      "5               0.995378          0.995428      0.990778     KNN  \n",
      "6               0.995291          0.995320      0.986696     KNN  \n",
      "7               0.995553          0.995604      0.983624     KNN  \n",
      "8               0.994070          0.994131      0.983761     KNN  \n",
      "9               0.994244          0.994268      0.979468     KNN  \n",
      "10              0.991280          0.990700      0.997734     SVM  \n",
      "11              0.992326          0.991967      0.997981     SVM  \n",
      "12              0.992850          0.992566      0.997851     SVM  \n",
      "13              0.993372          0.993286      0.997254     SVM  \n",
      "14              0.993459          0.993214      0.998058     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              1.000000          1.000000      1.000000     GNB  \n",
      "17              1.000000          1.000000      1.000000     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "1265.2482451999676\n"
     ]
    }
   ],
   "source": [
    "## Train: Binary, Test: in-browser (stealthy)\n",
    " \n",
    "df_malicious_Train = pd.concat([df4])\n",
    "df_malicious_Test = pd.concat([df33])\n",
    "\n",
    "\n",
    "df_benign_Train = pd.concat([df13,df14,df15,df16,df17])\n",
    "df_benign_Test = pd.concat([df13,df14,df15,df16,df17])\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 12871\n",
      "malicious_test: 9880\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n",
      "After droppping NAN rows: \n",
      "malicious_train: 12871\n",
      "malicious_test: 9880\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:11<00:00,  3.49it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:09<00:00,  4.23it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [07:30<00:00, 11.26s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [07:29<00:00, 11.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     56163\n",
      "      benign       0.89      0.76      0.82       988\n",
      "\n",
      "    accuracy                           0.99     57151\n",
      "   macro avg       0.94      0.88      0.91     57151\n",
      "weighted avg       0.99      0.99      0.99     57151\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.956954    0.023998       0.993212                 0.992938   \n",
      "1  0.993132    0.017992       0.992689                 0.992490   \n",
      "2  0.960059    0.018992       0.993299                 0.993031   \n",
      "3  0.977358    0.019997       0.993734                 0.993500   \n",
      "4  0.951217    0.016986       0.994430                 0.994235   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.993212          0.992911      0.983630  LogReg  \n",
      "1              0.992689          0.992566      0.984954  LogReg  \n",
      "2              0.993299          0.993084      0.989484  LogReg  \n",
      "3              0.993734          0.993445      0.988424  LogReg  \n",
      "4              0.994430          0.994253      0.983890  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      0.99     56163\n",
      "      benign       0.82      0.50      0.62       988\n",
      "\n",
      "    accuracy                           0.99     57151\n",
      "   macro avg       0.91      0.75      0.81     57151\n",
      "weighted avg       0.99      0.99      0.99     57151\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  0.956954    0.023998       0.993212                 0.992938   \n",
      "1  0.993132    0.017992       0.992689                 0.992490   \n",
      "2  0.960059    0.018992       0.993299                 0.993031   \n",
      "3  0.977358    0.019997       0.993734                 0.993500   \n",
      "4  0.951217    0.016986       0.994430                 0.994235   \n",
      "5  0.093050    2.665922       0.986859                 0.985646   \n",
      "6  0.094018    2.614976       0.986858                 0.985618   \n",
      "7  0.088000    2.618968       0.988338                 0.987311   \n",
      "8  0.088000    2.648087       0.987990                 0.986996   \n",
      "9  0.087992    2.663530       0.986858                 0.985546   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.993212          0.992911      0.983630  LogReg  \n",
      "1              0.992689          0.992566      0.984954  LogReg  \n",
      "2              0.993299          0.993084      0.989484  LogReg  \n",
      "3              0.993734          0.993445      0.988424  LogReg  \n",
      "4              0.994430          0.994253      0.983890  LogReg  \n",
      "5              0.986859          0.985864      0.922946     KNN  \n",
      "6              0.986858          0.985477      0.921501     KNN  \n",
      "7              0.988338          0.987353      0.917900     KNN  \n",
      "8              0.987990          0.987208      0.932282     KNN  \n",
      "9              0.986858          0.985842      0.924071     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.99      1.00      1.00     56163\n",
      "      benign       0.93      0.49      0.64       988\n",
      "\n",
      "    accuracy                           0.99     57151\n",
      "   macro avg       0.96      0.75      0.82     57151\n",
      "weighted avg       0.99      0.99      0.99     57151\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    0.956954    0.023998       0.993212                 0.992938   \n",
      "1    0.993132    0.017992       0.992689                 0.992490   \n",
      "2    0.960059    0.018992       0.993299                 0.993031   \n",
      "3    0.977358    0.019997       0.993734                 0.993500   \n",
      "4    0.951217    0.016986       0.994430                 0.994235   \n",
      "5    0.093050    2.665922       0.986859                 0.985646   \n",
      "6    0.094018    2.614976       0.986858                 0.985618   \n",
      "7    0.088000    2.618968       0.988338                 0.987311   \n",
      "8    0.088000    2.648087       0.987990                 0.986996   \n",
      "9    0.087992    2.663530       0.986858                 0.985546   \n",
      "10  15.971166    8.512795       0.988687                 0.988380   \n",
      "11  15.746044    9.010365       0.987293                 0.986995   \n",
      "12  15.930941    8.730793       0.987728                 0.987314   \n",
      "13  15.554149    8.751059       0.988425                 0.988010   \n",
      "14  16.564907    9.116137       0.988512                 0.987794   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.993212          0.992911      0.983630  LogReg  \n",
      "1               0.992689          0.992566      0.984954  LogReg  \n",
      "2               0.993299          0.993084      0.989484  LogReg  \n",
      "3               0.993734          0.993445      0.988424  LogReg  \n",
      "4               0.994430          0.994253      0.983890  LogReg  \n",
      "5               0.986859          0.985864      0.922946     KNN  \n",
      "6               0.986858          0.985477      0.921501     KNN  \n",
      "7               0.988338          0.987353      0.917900     KNN  \n",
      "8               0.987990          0.987208      0.932282     KNN  \n",
      "9               0.986858          0.985842      0.924071     KNN  \n",
      "10              0.988687          0.987096      0.898659     SVM  \n",
      "11              0.987293          0.985182      0.909319     SVM  \n",
      "12              0.987728          0.985653      0.882796     SVM  \n",
      "13              0.988425          0.986703      0.898906     SVM  \n",
      "14              0.988512          0.986924      0.913692     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       1.00      1.00      1.00     56163\n",
      "      benign       1.00      1.00      1.00       988\n",
      "\n",
      "    accuracy                           1.00     57151\n",
      "   macro avg       1.00      1.00      1.00     57151\n",
      "weighted avg       1.00      1.00      1.00     57151\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    0.956954    0.023998       0.993212                 0.992938   \n",
      "1    0.993132    0.017992       0.992689                 0.992490   \n",
      "2    0.960059    0.018992       0.993299                 0.993031   \n",
      "3    0.977358    0.019997       0.993734                 0.993500   \n",
      "4    0.951217    0.016986       0.994430                 0.994235   \n",
      "5    0.093050    2.665922       0.986859                 0.985646   \n",
      "6    0.094018    2.614976       0.986858                 0.985618   \n",
      "7    0.088000    2.618968       0.988338                 0.987311   \n",
      "8    0.088000    2.648087       0.987990                 0.986996   \n",
      "9    0.087992    2.663530       0.986858                 0.985546   \n",
      "10  15.971166    8.512795       0.988687                 0.988380   \n",
      "11  15.746044    9.010365       0.987293                 0.986995   \n",
      "12  15.930941    8.730793       0.987728                 0.987314   \n",
      "13  15.554149    8.751059       0.988425                 0.988010   \n",
      "14  16.564907    9.116137       0.988512                 0.987794   \n",
      "15   0.243504    0.112925       0.998956                 0.998957   \n",
      "16   0.234643    0.100064       0.999217                 0.999217   \n",
      "17   0.204117    0.135968       0.999826                 0.999826   \n",
      "18   0.291975    0.097000       0.999217                 0.999217   \n",
      "19   0.188933    0.105420       0.998869                 0.998870   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.993212          0.992911      0.983630  LogReg  \n",
      "1               0.992689          0.992566      0.984954  LogReg  \n",
      "2               0.993299          0.993084      0.989484  LogReg  \n",
      "3               0.993734          0.993445      0.988424  LogReg  \n",
      "4               0.994430          0.994253      0.983890  LogReg  \n",
      "5               0.986859          0.985864      0.922946     KNN  \n",
      "6               0.986858          0.985477      0.921501     KNN  \n",
      "7               0.988338          0.987353      0.917900     KNN  \n",
      "8               0.987990          0.987208      0.932282     KNN  \n",
      "9               0.986858          0.985842      0.924071     KNN  \n",
      "10              0.988687          0.987096      0.898659     SVM  \n",
      "11              0.987293          0.985182      0.909319     SVM  \n",
      "12              0.987728          0.985653      0.882796     SVM  \n",
      "13              0.988425          0.986703      0.898906     SVM  \n",
      "14              0.988512          0.986924      0.913692     SVM  \n",
      "15              0.998956          0.998944      1.000000     GNB  \n",
      "16              0.999217          0.999210      0.996283     GNB  \n",
      "17              0.999826          0.999826      1.000000     GNB  \n",
      "18              0.999217          0.999210      1.000000     GNB  \n",
      "19              0.998869          0.998854      0.997967     GNB  \n",
      "1309.275046500028\n"
     ]
    }
   ],
   "source": [
    "## Train: in-browser (aggressive), Test: in-browser (stealthy)\n",
    " \n",
    "df_malicious_Train = pd.concat([df5])\n",
    "df_malicious_Test = pd.concat([df33])\n",
    "\n",
    "\n",
    "df_benign_Train = pd.concat([df13,df14,df15,df16,df17])\n",
    "df_benign_Test = pd.concat([df13,df14,df15,df16,df17])\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious_train: 11745\n",
      "malicious_test: 16744\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n",
      "After droppping NAN rows: \n",
      "malicious_train: 11745\n",
      "malicious_test: 16744\n",
      "benign_train: 561625\n",
      "benign_test: 561625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:10<00:00,  3.64it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:14<00:00,  2.70it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [07:27<00:00, 11.19s/it]\n",
      "Feature Extraction: 100%|██████████| 40/40 [07:28<00:00, 11.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let the ml starts\n",
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      1.00      0.99     56163\n",
      "      benign       0.71      0.13      0.22      1675\n",
      "\n",
      "    accuracy                           0.97     57838\n",
      "   macro avg       0.84      0.56      0.60     57838\n",
      "weighted avg       0.97      0.97      0.96     57838\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.028337    0.019996       0.997820                 0.997846   \n",
      "1  1.030248    0.021011       0.997733                 0.997704   \n",
      "2  1.111039    0.018003       0.998343                 0.998365   \n",
      "3  1.233609    0.021995       0.996773                 0.996867   \n",
      "4  1.069401    0.017989       0.998256                 0.998249   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997820          0.997831      0.999633  LogReg  \n",
      "1              0.997733          0.997709      0.999634  LogReg  \n",
      "2              0.998343          0.998352      0.999773  LogReg  \n",
      "3              0.996773          0.996810      0.999061  LogReg  \n",
      "4              0.998256          0.998252      0.999784  LogReg  \n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      1.00      0.99     56163\n",
      "      benign       0.66      0.09      0.16      1675\n",
      "\n",
      "    accuracy                           0.97     57838\n",
      "   macro avg       0.81      0.55      0.57     57838\n",
      "weighted avg       0.96      0.97      0.96     57838\n",
      "\n",
      "   fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0  1.028337    0.019996       0.997820                 0.997846   \n",
      "1  1.030248    0.021011       0.997733                 0.997704   \n",
      "2  1.111039    0.018003       0.998343                 0.998365   \n",
      "3  1.233609    0.021995       0.996773                 0.996867   \n",
      "4  1.069401    0.017989       0.998256                 0.998249   \n",
      "5  0.087000    2.709012       0.995378                 0.995497   \n",
      "6  0.084000    2.737195       0.995291                 0.995354   \n",
      "7  0.071992    2.720438       0.995553                 0.995676   \n",
      "8  0.080000    2.684395       0.994070                 0.994208   \n",
      "9  0.085000    2.725298       0.994244                 0.994295   \n",
      "\n",
      "   test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0              0.997820          0.997831      0.999633  LogReg  \n",
      "1              0.997733          0.997709      0.999634  LogReg  \n",
      "2              0.998343          0.998352      0.999773  LogReg  \n",
      "3              0.996773          0.996810      0.999061  LogReg  \n",
      "4              0.998256          0.998252      0.999784  LogReg  \n",
      "5              0.995378          0.995428      0.990778     KNN  \n",
      "6              0.995291          0.995320      0.986696     KNN  \n",
      "7              0.995553          0.995604      0.983624     KNN  \n",
      "8              0.994070          0.994131      0.983761     KNN  \n",
      "9              0.994244          0.994268      0.979468     KNN  \n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      1.00      0.99     56163\n",
      "      benign       0.58      0.11      0.18      1675\n",
      "\n",
      "    accuracy                           0.97     57838\n",
      "   macro avg       0.78      0.55      0.58     57838\n",
      "weighted avg       0.96      0.97      0.96     57838\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.028337    0.019996       0.997820                 0.997846   \n",
      "1    1.030248    0.021011       0.997733                 0.997704   \n",
      "2    1.111039    0.018003       0.998343                 0.998365   \n",
      "3    1.233609    0.021995       0.996773                 0.996867   \n",
      "4    1.069401    0.017989       0.998256                 0.998249   \n",
      "5    0.087000    2.709012       0.995378                 0.995497   \n",
      "6    0.084000    2.737195       0.995291                 0.995354   \n",
      "7    0.071992    2.720438       0.995553                 0.995676   \n",
      "8    0.080000    2.684395       0.994070                 0.994208   \n",
      "9    0.085000    2.725298       0.994244                 0.994295   \n",
      "10  14.226315    9.118626       0.991280                 0.990741   \n",
      "11  14.255270    8.881189       0.992326                 0.991924   \n",
      "12  14.284246    8.932623       0.992850                 0.992496   \n",
      "13  14.210603    8.816179       0.993372                 0.993224   \n",
      "14  14.328421    9.169561       0.993459                 0.993170   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997820          0.997831      0.999633  LogReg  \n",
      "1               0.997733          0.997709      0.999634  LogReg  \n",
      "2               0.998343          0.998352      0.999773  LogReg  \n",
      "3               0.996773          0.996810      0.999061  LogReg  \n",
      "4               0.998256          0.998252      0.999784  LogReg  \n",
      "5               0.995378          0.995428      0.990778     KNN  \n",
      "6               0.995291          0.995320      0.986696     KNN  \n",
      "7               0.995553          0.995604      0.983624     KNN  \n",
      "8               0.994070          0.994131      0.983761     KNN  \n",
      "9               0.994244          0.994268      0.979468     KNN  \n",
      "10              0.991280          0.990700      0.997734     SVM  \n",
      "11              0.992326          0.991967      0.997981     SVM  \n",
      "12              0.992850          0.992566      0.997851     SVM  \n",
      "13              0.993372          0.993286      0.997254     SVM  \n",
      "14              0.993459          0.993214      0.998058     SVM  \n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.97      1.00      0.99     56163\n",
      "      benign       0.00      0.00      0.00      1675\n",
      "\n",
      "    accuracy                           0.97     57838\n",
      "   macro avg       0.49      0.50      0.49     57838\n",
      "weighted avg       0.94      0.97      0.96     57838\n",
      "\n",
      "     fit_time  score_time  test_accuracy  test_precision_weighted  \\\n",
      "0    1.028337    0.019996       0.997820                 0.997846   \n",
      "1    1.030248    0.021011       0.997733                 0.997704   \n",
      "2    1.111039    0.018003       0.998343                 0.998365   \n",
      "3    1.233609    0.021995       0.996773                 0.996867   \n",
      "4    1.069401    0.017989       0.998256                 0.998249   \n",
      "5    0.087000    2.709012       0.995378                 0.995497   \n",
      "6    0.084000    2.737195       0.995291                 0.995354   \n",
      "7    0.071992    2.720438       0.995553                 0.995676   \n",
      "8    0.080000    2.684395       0.994070                 0.994208   \n",
      "9    0.085000    2.725298       0.994244                 0.994295   \n",
      "10  14.226315    9.118626       0.991280                 0.990741   \n",
      "11  14.255270    8.881189       0.992326                 0.991924   \n",
      "12  14.284246    8.932623       0.992850                 0.992496   \n",
      "13  14.210603    8.816179       0.993372                 0.993224   \n",
      "14  14.328421    9.169561       0.993459                 0.993170   \n",
      "15   0.181108    0.142276       1.000000                 1.000000   \n",
      "16   0.214802    0.122927       1.000000                 1.000000   \n",
      "17   0.241062    0.125977       1.000000                 1.000000   \n",
      "18   0.237231    0.119358       1.000000                 1.000000   \n",
      "19   0.219948    0.126366       1.000000                 1.000000   \n",
      "\n",
      "    test_recall_weighted  test_f1_weighted  test_roc_auc   model  \n",
      "0               0.997820          0.997831      0.999633  LogReg  \n",
      "1               0.997733          0.997709      0.999634  LogReg  \n",
      "2               0.998343          0.998352      0.999773  LogReg  \n",
      "3               0.996773          0.996810      0.999061  LogReg  \n",
      "4               0.998256          0.998252      0.999784  LogReg  \n",
      "5               0.995378          0.995428      0.990778     KNN  \n",
      "6               0.995291          0.995320      0.986696     KNN  \n",
      "7               0.995553          0.995604      0.983624     KNN  \n",
      "8               0.994070          0.994131      0.983761     KNN  \n",
      "9               0.994244          0.994268      0.979468     KNN  \n",
      "10              0.991280          0.990700      0.997734     SVM  \n",
      "11              0.992326          0.991967      0.997981     SVM  \n",
      "12              0.992850          0.992566      0.997851     SVM  \n",
      "13              0.993372          0.993286      0.997254     SVM  \n",
      "14              0.993459          0.993214      0.998058     SVM  \n",
      "15              1.000000          1.000000      1.000000     GNB  \n",
      "16              1.000000          1.000000      1.000000     GNB  \n",
      "17              1.000000          1.000000      1.000000     GNB  \n",
      "18              1.000000          1.000000      1.000000     GNB  \n",
      "19              1.000000          1.000000      1.000000     GNB  \n",
      "1296.4210934999865\n"
     ]
    }
   ],
   "source": [
    "## Train: in-browser (aggressive), Test: in-browser (robust)\n",
    " \n",
    "df_malicious_Train = pd.concat([df4])\n",
    "df_malicious_Test = pd.concat([df32])\n",
    "\n",
    "\n",
    "df_benign_Train = pd.concat([df13,df14,df15,df16,df17])\n",
    "df_benign_Test = pd.concat([df13,df14,df15,df16,df17])\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "#print(\"{} NAN in malicious!\".format(len(df_malicious[df_malicious.isna().any(axis=1)])))\n",
    "#print(\"{} NAN in benign!\".format(len(df_benign[df_benign.isna().any(axis=1)])))\n",
    "\n",
    "df_malicious_Test = df_malicious_Test.dropna()\n",
    "df_malicious_Train = df_malicious_Train.dropna()\n",
    "\n",
    "df_benign_Test = df_benign_Test.dropna()\n",
    "df_benign_Train = df_benign_Train.dropna()\n",
    "\n",
    "print(\"After droppping NAN rows: \")\n",
    "\n",
    "print(\"malicious_train: {}\".format(len(df_malicious_Train)))\n",
    "print(\"malicious_test: {}\".format(len(df_malicious_Test)))\n",
    "\n",
    "print(\"benign_train: {}\".format(len(df_benign_Train)))\n",
    "print(\"benign_test: {}\".format(len(df_benign_Test)))\n",
    "\n",
    "start = timer()\n",
    "\n",
    "results_all_combined_s0 = run_process(df_malicious_Train,df_benign_Train,df_malicious_Test,df_benign_Test)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
